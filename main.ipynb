{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main\n"
     ]
    }
   ],
   "source": [
    "print(\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single ID Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspaces/Masterthesis-DRF\n"
     ]
    }
   ],
   "source": [
    "from scripts.shared_imports import *\n",
    "\n",
    "# Verify that the current working directory has changed\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Importiere alle Module\n",
    "from scripts.get_data import get_dataset_settings_singleID, preprocess_data_singleID\n",
    "from Wrapper.wrapper import DRFWrapper, MLPRegressorWrapper\n",
    "from scripts.utils import *\n",
    "from scripts.train_and_evaluate_singleID import (  \n",
    "    append_result, evaluate_and_append_models_singleID, create_cv_folds_singleID,preprocess_per_instance_singleID\n",
    ")\n",
    "from scripts.process_target import process_target_singleID\n",
    "\n",
    "import scripts.config as config\n",
    "from scripts.globals import global_fold_scores, global_cv_results, drf_cv_results\n",
    "\n",
    "# Lade alle Module neu\n",
    "importlib.reload(config)\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'  # OpenMP Threads auf 4 beschränken\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'  # Für OpenBLAS\n",
    "os.environ['MKL_NUM_THREADS'] = '1'  # Für Intel MKL (falls verwendet)\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'  # Für NumExpr\n",
    "os.environ['VECLIB_MAXIMUM_THREADS'] = '1'  # Für MacOS Accelerate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set configurations in config.py file before we start process\n",
    "\n",
    "--> set dataset_name before in config file\n",
    "\n",
    "--> set levelset_calcuations to False if we do the basic models calcuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1xrY3Uv5F9F9ofgSM7dVoSK4bE0gPMg36\n",
      "To: /workspaces/Masterthesis-DRF/yaz.csv\n",
      "100%|██████████| 3.13M/3.13M [00:00<00:00, 233MB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dayIndex</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>weekend</th>\n",
       "      <th>wind</th>\n",
       "      <th>clouds</th>\n",
       "      <th>rain</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>label</th>\n",
       "      <th>scalingValue</th>\n",
       "      <th>demand__sum_values_7</th>\n",
       "      <th>demand__median_7</th>\n",
       "      <th>demand__mean_7</th>\n",
       "      <th>demand__standard_deviation_7</th>\n",
       "      <th>demand__variance_7</th>\n",
       "      <th>demand__root_mean_square_7</th>\n",
       "      <th>demand__maximum_7</th>\n",
       "      <th>demand__absolute_maximum_7</th>\n",
       "      <th>demand__minimum_7</th>\n",
       "      <th>demand__sum_values_14</th>\n",
       "      <th>demand__median_14</th>\n",
       "      <th>demand__mean_14</th>\n",
       "      <th>demand__standard_deviation_14</th>\n",
       "      <th>demand__variance_14</th>\n",
       "      <th>demand__root_mean_square_14</th>\n",
       "      <th>demand__maximum_14</th>\n",
       "      <th>demand__absolute_maximum_14</th>\n",
       "      <th>demand__minimum_14</th>\n",
       "      <th>demand__sum_values_28</th>\n",
       "      <th>demand__median_28</th>\n",
       "      <th>demand__mean_28</th>\n",
       "      <th>demand__standard_deviation_28</th>\n",
       "      <th>demand__variance_28</th>\n",
       "      <th>demand__root_mean_square_28</th>\n",
       "      <th>demand__maximum_28</th>\n",
       "      <th>demand__absolute_maximum_28</th>\n",
       "      <th>demand__minimum_28</th>\n",
       "      <th>demand</th>\n",
       "      <th>id</th>\n",
       "      <th>weekday_FRI</th>\n",
       "      <th>weekday_MON</th>\n",
       "      <th>weekday_SAT</th>\n",
       "      <th>weekday_SUN</th>\n",
       "      <th>weekday_THU</th>\n",
       "      <th>weekday_TUE</th>\n",
       "      <th>weekday_WED</th>\n",
       "      <th>month_APR</th>\n",
       "      <th>month_AUG</th>\n",
       "      <th>month_DEC</th>\n",
       "      <th>month_FEB</th>\n",
       "      <th>month_JAN</th>\n",
       "      <th>month_JUL</th>\n",
       "      <th>month_JUN</th>\n",
       "      <th>month_MAR</th>\n",
       "      <th>month_MAY</th>\n",
       "      <th>month_NOV</th>\n",
       "      <th>month_OCT</th>\n",
       "      <th>month_SEP</th>\n",
       "      <th>year_2013</th>\n",
       "      <th>year_2014</th>\n",
       "      <th>year_2015</th>\n",
       "      <th>dayCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.309307</td>\n",
       "      <td>0.068571</td>\n",
       "      <td>5.168586</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.762709</td>\n",
       "      <td>0.124286</td>\n",
       "      <td>5.775564</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>2.011130</td>\n",
       "      <td>0.161786</td>\n",
       "      <td>5.622023</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>calamari</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>train</td>\n",
       "      <td>25.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>2.185294</td>\n",
       "      <td>0.191020</td>\n",
       "      <td>4.810702</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.203893</td>\n",
       "      <td>0.194286</td>\n",
       "      <td>5.464169</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.035714</td>\n",
       "      <td>2.227781</td>\n",
       "      <td>0.198520</td>\n",
       "      <td>5.506490</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>calamari</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>train</td>\n",
       "      <td>25.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>7.553888</td>\n",
       "      <td>2.282449</td>\n",
       "      <td>10.494897</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.071429</td>\n",
       "      <td>5.522219</td>\n",
       "      <td>1.219796</td>\n",
       "      <td>8.207140</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.642857</td>\n",
       "      <td>4.302942</td>\n",
       "      <td>0.740612</td>\n",
       "      <td>7.096277</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>calamari</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>train</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>7.687785</td>\n",
       "      <td>2.364082</td>\n",
       "      <td>10.113640</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>5.578750</td>\n",
       "      <td>1.244898</td>\n",
       "      <td>8.088793</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.535714</td>\n",
       "      <td>4.329980</td>\n",
       "      <td>0.749949</td>\n",
       "      <td>7.028005</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>calamari</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>314.0</td>\n",
       "      <td>train</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>8.025470</td>\n",
       "      <td>2.576327</td>\n",
       "      <td>9.935506</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>5.778655</td>\n",
       "      <td>1.335714</td>\n",
       "      <td>7.977647</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.392857</td>\n",
       "      <td>4.442805</td>\n",
       "      <td>0.789541</td>\n",
       "      <td>6.987233</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>calamari</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>train</td>\n",
       "      <td>82.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.857143</td>\n",
       "      <td>9.062144</td>\n",
       "      <td>1.001493</td>\n",
       "      <td>30.246605</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.928571</td>\n",
       "      <td>8.589564</td>\n",
       "      <td>0.899764</td>\n",
       "      <td>30.176860</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>30.178571</td>\n",
       "      <td>12.736487</td>\n",
       "      <td>1.978270</td>\n",
       "      <td>32.756134</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>steak</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>train</td>\n",
       "      <td>82.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>9.332847</td>\n",
       "      <td>1.062220</td>\n",
       "      <td>30.057089</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>28.142857</td>\n",
       "      <td>8.951114</td>\n",
       "      <td>0.977103</td>\n",
       "      <td>29.532065</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.857143</td>\n",
       "      <td>12.899929</td>\n",
       "      <td>2.029368</td>\n",
       "      <td>32.524716</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>steak</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4449</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>82.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.285714</td>\n",
       "      <td>8.275856</td>\n",
       "      <td>0.835241</td>\n",
       "      <td>31.396087</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>28.357143</td>\n",
       "      <td>8.957097</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>29.738143</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.142857</td>\n",
       "      <td>12.304802</td>\n",
       "      <td>1.846441</td>\n",
       "      <td>31.634068</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>steak</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>82.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.285714</td>\n",
       "      <td>8.310308</td>\n",
       "      <td>0.842210</td>\n",
       "      <td>30.441982</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>28.357143</td>\n",
       "      <td>8.957097</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>29.738143</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.642857</td>\n",
       "      <td>12.136763</td>\n",
       "      <td>1.796354</td>\n",
       "      <td>31.108106</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>steak</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>train</td>\n",
       "      <td>82.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.285714</td>\n",
       "      <td>8.310308</td>\n",
       "      <td>0.842210</td>\n",
       "      <td>30.441982</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>27.714286</td>\n",
       "      <td>8.704913</td>\n",
       "      <td>0.924092</td>\n",
       "      <td>29.049219</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.464286</td>\n",
       "      <td>11.181880</td>\n",
       "      <td>1.524810</td>\n",
       "      <td>31.514736</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>steak</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dayIndex  is_holiday  is_closed  weekend  wind  clouds  rain  sunshine  label  scalingValue  demand__sum_values_7  demand__median_7  demand__mean_7  demand__standard_deviation_7  demand__variance_7  demand__root_mean_square_7  demand__maximum_7  demand__absolute_maximum_7  demand__minimum_7  demand__sum_values_14  demand__median_14  demand__mean_14  demand__standard_deviation_14  demand__variance_14  demand__root_mean_square_14  demand__maximum_14  demand__absolute_maximum_14  demand__minimum_14  demand__sum_values_28  demand__median_28  demand__mean_28  demand__standard_deviation_28  demand__variance_28  demand__root_mean_square_28  demand__maximum_28  demand__absolute_maximum_28  demand__minimum_28  demand        id  weekday_FRI  weekday_MON  weekday_SAT  weekday_SUN  weekday_THU  weekday_TUE  weekday_WED  month_APR  month_AUG  month_DEC  month_FEB  month_JAN  month_JUL  month_JUN  month_MAR  month_MAY  month_NOV  month_OCT  month_SEP  year_2013  year_2014  year_2015  \\\n",
       "0         29.0         1.0        0.0      0.0   2.6     7.7   0.0       0.0  train          25.0                  35.0               5.0        5.000000                      1.309307            0.068571                    5.168586                8.0                         8.0                4.0                   77.0                5.0         5.500000                       1.762709             0.124286                     5.775564                10.0                         10.0                 3.0                  147.0                5.0         5.250000                       2.011130             0.161786                     5.622023                10.0                         10.0                 1.0     0.0  calamari            1            0            0            0            0            0            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "1         30.0         0.0        0.0      1.0   4.4     7.1   0.0      60.0  train          25.0                  30.0               4.0        4.285714                      2.185294            0.191020                    4.810702                8.0                         8.0                0.0                   70.0                5.0         5.000000                       2.203893             0.194286                     5.464169                10.0                         10.0                 0.0                  141.0                5.0         5.035714                       2.227781             0.198520                     5.506490                10.0                         10.0                 0.0    25.0  calamari            0            0            1            0            0            0            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "2         31.0         0.0        0.0      1.0   4.8     3.0   0.0     258.0  train          25.0                  51.0               5.0        7.285714                      7.553888            2.282449                   10.494897               25.0                        25.0                0.0                   85.0                5.0         6.071429                       5.522219             1.219796                     8.207140                25.0                         25.0                 0.0                  158.0                5.0         5.642857                       4.302942             0.740612                     7.096277                25.0                         25.0                 0.0     3.0  calamari            0            0            0            1            0            0            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "3         32.0         0.0        0.0      0.0   5.1     7.6   0.1      19.0  train          25.0                  46.0               4.0        6.571429                      7.687785            2.364082                   10.113640               25.0                        25.0                0.0                   82.0                5.0         5.857143                       5.578750             1.244898                     8.088793                25.0                         25.0                 0.0                  155.0                5.0         5.535714                       4.329980             0.749949                     7.028005                25.0                         25.0                 0.0     0.0  calamari            0            1            0            0            0            0            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "4         33.0         0.0        0.0      0.0   3.5     4.4   0.3     314.0  train          25.0                  41.0               4.0        5.857143                      8.025470            2.576327                    9.935506               25.0                        25.0                0.0                   77.0                4.5         5.500000                       5.778655             1.335714                     7.977647                25.0                         25.0                 0.0                  151.0                5.0         5.392857                       4.442805             0.789541                     6.987233                25.0                         25.0                 0.0     2.0  calamari            0            0            0            0            0            1            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "...        ...         ...        ...      ...   ...     ...   ...       ...    ...           ...                   ...               ...             ...                           ...                 ...                         ...                ...                         ...                ...                    ...                ...              ...                            ...                  ...                          ...                 ...                          ...                 ...                    ...                ...              ...                            ...                  ...                          ...                 ...                          ...                 ...     ...       ...          ...          ...          ...          ...          ...          ...          ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...   \n",
       "4447      54.0         0.0        0.0      0.0   3.0     5.5   0.0     125.0  train          82.0                 202.0              27.0       28.857143                      9.062144            1.001493                   30.246605               48.0                        48.0               18.0                  405.0               27.0        28.928571                       8.589564             0.899764                    30.176860                48.0                         48.0                18.0                  845.0               26.5        30.178571                      12.736487             1.978270                    32.756134                59.0                         59.0                 4.0    19.0     steak            0            0            0            0            0            1            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "4448      55.0         0.0        0.0      0.0   1.5     1.9   0.0     288.0  train          82.0                 200.0              27.0       28.571429                      9.332847            1.062220                   30.057089               48.0                        48.0               18.0                  394.0               26.5        28.142857                       8.951114             0.977103                    29.532065                48.0                         48.0                18.0                  836.0               26.0        29.857143                      12.899929             2.029368                    32.524716                59.0                         59.0                 4.0    30.0     steak            0            0            0            0            0            0            1          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "4449      56.0         0.0        0.0      0.0   1.1     7.8   0.4       0.0  train          82.0                 212.0              29.0       30.285714                      8.275856            0.835241                   31.396087               48.0                        48.0               19.0                  397.0               26.5        28.357143                       8.957097             0.978410                    29.738143                48.0                         48.0                18.0                  816.0               26.0        29.142857                      12.304802             1.846441                    31.634068                59.0                         59.0                 4.0    26.0     steak            0            0            0            0            1            0            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "4450      57.0         0.0        0.0      0.0   3.4     7.9   0.0       0.0  train          82.0                 205.0              27.0       29.285714                      8.310308            0.842210                   30.441982               48.0                        48.0               19.0                  397.0               26.5        28.357143                       8.957097             0.978410                    29.738143                48.0                         48.0                18.0                  802.0               26.0        28.642857                      12.136763             1.796354                    31.108106                59.0                         59.0                 4.0    27.0     steak            1            0            0            0            0            0            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "4451      58.0         0.0        0.0      1.0   2.4     7.5   0.0     116.0  train          82.0                 205.0              27.0       29.285714                      8.310308            0.842210                   30.441982               48.0                        48.0               19.0                  388.0               26.5        27.714286                       8.704913             0.924092                    29.049219                48.0                         48.0                18.0                  825.0               26.0        29.464286                      11.181880             1.524810                    31.514736                59.0                         59.0                17.0    47.0     steak            0            0            1            0            0            0            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "\n",
       "      dayCount  \n",
       "0         29.0  \n",
       "1         30.0  \n",
       "2         31.0  \n",
       "3         32.0  \n",
       "4         33.0  \n",
       "...        ...  \n",
       "4447      54.0  \n",
       "4448      55.0  \n",
       "4449      56.0  \n",
       "4450      57.0  \n",
       "4451      58.0  \n",
       "\n",
       "[210 rows x 62 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>calamari</th>\n",
       "      <th>chicken</th>\n",
       "      <th>fish</th>\n",
       "      <th>koefte</th>\n",
       "      <th>lamb</th>\n",
       "      <th>shrimp</th>\n",
       "      <th>steak</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dayIndex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31.0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "id        calamari  chicken  fish  koefte  lamb  shrimp  steak\n",
       "dayIndex                                                      \n",
       "29.0           0.0      1.0   3.0     2.0   0.0     2.0    4.0\n",
       "30.0          25.0     78.0  14.0    71.0  63.0    23.0   59.0\n",
       "31.0           3.0     32.0   4.0    19.0  40.0     6.0   26.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Zeilen: 661\n",
      "Anzahl der targets: 7\n"
     ]
    }
   ],
   "source": [
    "dataset_name = config.dataset_name\n",
    "\n",
    "# Hole die Datei-ID für den gewählten Datensatz\n",
    "file_id = {\n",
    "    'bakery': '1r_bDn9Z3Q_XgeTTkJL7352nUG3jkUM0z',\n",
    "    'yaz': '1xrY3Uv5F9F9ofgSM7dVoSK4bE0gPMg36',\n",
    "    'm5': '1tCBaxOgE5HHllvLVeRC18zvALBz6B-6w',\n",
    "    'sid': '1J9bPCfeLDH-mbSnvTHRoCva7pl6cXD3_',\n",
    "    'air': '1SKPpNxulcusNTjRwCC0p3C_XW7aNBNJZ',\n",
    "    \"copula\": '1H5wdJgmxdhbzeS17w0NkRlHRCESEAd-e',\n",
    "    'wage': '1bn7E7NOoRzE4NwXXs1MYhRSKZHC13qYU',\n",
    "}[config.dataset_name]\n",
    "\n",
    "\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "\n",
    "# Datei herunterladen\n",
    "output = f\"{dataset_name}.csv\"\n",
    "gdown.download(url, output, quiet=False)\n",
    "data = pd.read_csv(output)\n",
    "\n",
    "# Erstelle die Dataset-Einstellungen basierend auf den geladenen Daten\n",
    "settings = get_dataset_settings_singleID(data)[dataset_name]\n",
    "\n",
    "y, train_data, test_data, X_train_features, X_test_features, y_train, y_test = preprocess_data_singleID(\n",
    "    data, settings['backscaling_columns'], settings['bool_columns'], settings['drop_columns'])\n",
    "\n",
    "\n",
    "display(X_train_features.head(30))\n",
    "display(y_train.head(3))\n",
    "print(f\"Anzahl der Zeilen: {len(y_train)}\")\n",
    "print(\"Anzahl der targets:\", len(y_train.columns))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process - DDOP Models + Levelset Estimator Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cu, co combination: cu=9, co=1\n",
      "Test length for column: 39 6 % of the actual ID: 661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function ThreadpoolController._find_libraries_with_dl_iterate_phdr.<locals>.match_library_callback at 0x769002feda60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/threadpoolctl.py\", line 1005, in match_library_callback\n",
      "    self._make_controller_from_path(filepath)\n",
      "  File \"/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/threadpoolctl.py\", line 1175, in _make_controller_from_path\n",
      "    lib_controller = controller_class(\n",
      "  File \"/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/threadpoolctl.py\", line 114, in __init__\n",
      "    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n",
      "  File \"/usr/lib/python3.8/ctypes/__init__.py\", line 373, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: dlopen() error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model MLP for column calamari, cu=9, co=1\n",
      "Evaluating model: MLP, cu: 9, co: 1\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Cross-validation results for MLP with cu=9, co=1:\n",
      "Running model LGBM for column calamari, cu=9, co=1\n",
      "Evaluating model: LGBM, cu: 9, co: 1\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Cross-validation results for LGBM with cu=9, co=1:\n",
      "Running model RFW for column calamari, cu=9, co=1\n",
      "Evaluating model: RFW, cu: 9, co: 1\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function ThreadpoolController._find_libraries_with_dl_iterate_phdr.<locals>.match_library_callback at 0x769002fe7af0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/threadpoolctl.py\", line 1005, in match_library_callback\n",
      "    self._make_controller_from_path(filepath)\n",
      "  File \"/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/threadpoolctl.py\", line 1175, in _make_controller_from_path\n",
      "    lib_controller = controller_class(\n",
      "  File \"/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/threadpoolctl.py\", line 114, in __init__\n",
      "    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n",
      "  File \"/usr/lib/python3.8/ctypes/__init__.py\", line 373, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: dlopen() error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results for RFW with cu=9, co=1:\n",
      "Running model KNNW for column calamari, cu=9, co=1\n",
      "Evaluating model: KNNW, cu: 9, co: 1\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Cross-validation results for KNNW with cu=9, co=1:\n",
      "Running model DTW for column calamari, cu=9, co=1\n",
      "Evaluating model: DTW, cu: 9, co: 1\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Cross-validation results for DTW with cu=9, co=1:\n",
      "Running model GKW for column calamari, cu=9, co=1\n",
      "Evaluating model: GKW, cu: 9, co: 1\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Cross-validation results for GKW with cu=9, co=1:\n",
      "   Variable  cu  co Model  Pinball Loss                                                                                                                            Best Params   delta C   sl\n",
      "0  calamari   9   1   SAA      0.511842                                                                                                                                    N/A       NaN  0.9\n",
      "1  calamari   9   1   MLP      0.494512  {'alpha': 0.001, 'early_stopping': True, 'layer1': 28, 'layer2': 114, 'learning_rate_init': 0.001, 'max_iter': 500, 'solver': 'adam'}  0.033858  0.9\n",
      "2  calamari   9   1  LGBM      0.393950                                  {'learning_rate': 0.01, 'max_depth': 2, 'min_data_in_leaf': 50, 'n_estimators': 50, 'num_leaves': 63}  0.230330  0.9\n",
      "3  calamari   9   1   RFW      0.431579                                                    {'max_depth': 4, 'max_features': None, 'min_samples_split': 32, 'n_estimators': 20}  0.156812  0.9\n",
      "4  calamari   9   1  KNNW      0.375000                                                                                                                    {'n_neighbors': 32}  0.267352  0.9\n",
      "5  calamari   9   1   DTW      0.398684                                                                                              {'max_depth': 4, 'min_samples_split': 64}  0.221080  0.9\n",
      "6  calamari   9   1   GKW      0.418421                                                                                                              {'kernel_bandwidth': 2.5}  0.182519  0.9\n",
      "Test length for column: 39 6 % of the actual ID: 661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function ThreadpoolController._find_libraries_with_dl_iterate_phdr.<locals>.match_library_callback at 0x7690064bdf70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/threadpoolctl.py\", line 1005, in match_library_callback\n",
      "    self._make_controller_from_path(filepath)\n",
      "  File \"/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/threadpoolctl.py\", line 1175, in _make_controller_from_path\n",
      "    lib_controller = controller_class(\n",
      "  File \"/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/threadpoolctl.py\", line 114, in __init__\n",
      "    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n",
      "  File \"/usr/lib/python3.8/ctypes/__init__.py\", line 373, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: dlopen() error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model MLP for column chicken, cu=9, co=1\n",
      "Evaluating model: MLP, cu: 9, co: 1\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m tau \u001b[38;5;241m=\u001b[39m cu \u001b[38;5;241m/\u001b[39m (cu \u001b[38;5;241m+\u001b[39m co)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Parallelize column processing within each combination with n_jobs=4 to limit threads\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m column_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_target_singleID\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mco\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Combine results from all columns and print after each column\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m column_results:\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/scripts/process_target.py:47\u001b[0m, in \u001b[0;36mprocess_target_singleID\u001b[0;34m(column, cu, co, tau, y_train, X_train_features, X_test_features, y_test, random_state)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for column \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, cu=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, co=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mco\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;66;03m# Evaluate and append the model\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m         \u001b[43mevaluate_and_append_models_singleID\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaa_pinball_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mco\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeseries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m result_table \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     50\u001b[0m     table_rows,\n\u001b[1;32m     51\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVariable\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mco\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPinball Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Params\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta C\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msl\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(result_table\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m7\u001b[39m))\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/scripts/train_and_evaluate_singleID.py:201\u001b[0m, in \u001b[0;36mevaluate_and_append_models_singleID\u001b[0;34m(models, X_train_scaled, X_test_scaled, y_train_col, y_test_col, saa_pinball_loss, tau, cu, co, column, table_rows, timeseries)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model, param_grid \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, cu: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, co: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mco\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 201\u001b[0m     pinball_loss_value, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_singleID\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mco\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (pinball_loss_value \u001b[38;5;241m/\u001b[39m saa_pinball_loss)\n\u001b[1;32m    208\u001b[0m     append_result(table_rows, column, cu, co, model_name, pinball_loss_value, best_params, delta, tau)\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/scripts/train_and_evaluate_singleID.py:70\u001b[0m, in \u001b[0;36mtrain_and_evaluate_singleID\u001b[0;34m(model_name, model, param_grid, X_train_scaled, X_test_scaled, y_train, y_test, tau, cu, co, timeseries, column)\u001b[0m\n\u001b[1;32m     63\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m CV\u001b[38;5;241m.\u001b[39mbestParams_perProb[tau]\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# else run the CV for non Levelset models \u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     model, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mbayesian_search_model_singleID\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mco\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Conditionally pass 'quantile' only for DRF\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDRF\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/scripts/train_and_evaluate_singleID.py:117\u001b[0m, in \u001b[0;36mbayesian_search_model_singleID\u001b[0;34m(model_name, model, param_grid, X_train, y_train, tau, cu, co, n_points, n_initial_points, n_jobs, column)\u001b[0m\n\u001b[1;32m    100\u001b[0m bayes_search \u001b[38;5;241m=\u001b[39m BayesSearchCV(\n\u001b[1;32m    101\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    102\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m     }\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Fit the model with Bayesian optimization\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m \u001b[43mbayes_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m best_model \u001b[38;5;241m=\u001b[39m bayes_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Only set cu and co for models that accept these parameters\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/skopt/searchcv.py:542\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesSearchCV doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support a callable refit, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt define an implicit score to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m     )\n\u001b[0;32m--> 542\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_train_score:\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/skopt/searchcv.py:599\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[0;32m--> 599\u001b[0m     optim_result, score_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points_adjusted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/skopt/searchcv.py:445\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[0;34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate n_jobs parameters and evaluate them in parallel.\"\"\"\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# get parameter values to evaluate\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# convert parameters to python native types\u001b[39;00m\n\u001b[1;32m    448\u001b[0m params \u001b[38;5;241m=\u001b[39m [[np\u001b[38;5;241m.\u001b[39marray(v)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m p] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:464\u001b[0m, in \u001b[0;36mOptimizer.ask\u001b[0;34m(self, n_points, strategy)\u001b[0m\n\u001b[1;32m    462\u001b[0m         opt\u001b[38;5;241m.\u001b[39m_tell(x, (y_lie, t_lie))\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m         \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_lie\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_ \u001b[38;5;241m=\u001b[39m {(n_points, strategy): X}  \u001b[38;5;66;03m# cache_ the result\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:615\u001b[0m, in \u001b[0;36mOptimizer._tell\u001b[0;34m(self, x, y, fit)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    614\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 615\u001b[0m     est\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXi\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myi)\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_xs_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macq_func \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgp_hedge\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgains_ \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m est\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mvstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_xs_))\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/skopt/space/space.py:1245\u001b[0m, in \u001b[0;36mSpace.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;66;03m# Transform\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dims):\n\u001b[0;32m-> 1245\u001b[0m     columns[j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdimensions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;66;03m# Repack as an array\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m Xt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([np\u001b[38;5;241m.\u001b[39masarray(c)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;28mlen\u001b[39m(X), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m columns])\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/skopt/space/space.py:261\u001b[0m, in \u001b[0;36mDimension.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transform samples form the original space to a warped space.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/skopt/space/transformers.py:130\u001b[0m, in \u001b[0;36mCategoricalEncoder.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transform an array of categories to a one-hot encoded representation.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m        The one-hot encoded categories.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapping_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:357\u001b[0m, in \u001b[0;36mLabelBinarizer.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_is_multilabel \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_type_\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe object was not fitted with multilabel input.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 357\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlabel_binarize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneg_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneg_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:519\u001b[0m, in \u001b[0;36mlabel_binarize\u001b[0;34m(y, classes, neg_label, pos_label, sparse_output)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos_switch:\n\u001b[1;32m    517\u001b[0m     pos_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mneg_label\n\u001b[0;32m--> 519\u001b[0m y_type \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultioutput\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m y_type:\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultioutput target data is not supported with label binarization\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    523\u001b[0m     )\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/sklearn/utils/multiclass.py:311\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse_pandas:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseSeries\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseArray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_multilabel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# DeprecationWarning will be replaced by ValueError, see NEP 34\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# https://numpy.org/neps/nep-0034-infer-dtype-is-object.html\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# We therefore catch both deprecation (NumPy < 1.24) warning and\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# value error (NumPy >= 1.24).\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/sklearn/utils/multiclass.py:167\u001b[0m, in \u001b[0;36mis_multilabel\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    165\u001b[0m warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, VisibleDeprecationWarning)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_y_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (VisibleDeprecationWarning, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/sklearn/utils/_array_api.py:384\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    380\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/workspaces/Masterthesis-DRF/.venv/lib/python3.8/site-packages/sklearn/utils/_array_api.py:253\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.asarray\u001b[0;34m(self, x, dtype, device, copy)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39marray(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m(x, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Execution starts here\n",
    "combinations = [(9, 1), (7.5, 2.5), (5, 5), (2.5, 7.5), (1, 9)]\n",
    "table_rows = []\n",
    "random_state = 42\n",
    "\n",
    "# Initialize cvFolds\n",
    "cvFolds = None  # Initialization\n",
    "\n",
    "\n",
    "import scripts.globals as globals  # Import the globals module\n",
    "\n",
    "for cu, co in combinations:\n",
    "    print(f\"Processing cu, co combination: cu={cu}, co={co}\")\n",
    "    tau = cu / (cu + co)\n",
    "\n",
    "    # Parallelize column processing within each combination with n_jobs=4 to limit threads\n",
    "    column_results = Parallel(n_jobs=1)(  \n",
    "        delayed(process_target_singleID)(column, cu, co, tau, y_train, X_train_features, X_test_features, y_test, random_state)\n",
    "        for column in y_train.columns\n",
    "    )\n",
    "\n",
    "    # Combine results from all columns and print after each column\n",
    "    for result in column_results:\n",
    "        table_rows.extend(result)\n",
    "        print(table_rows)\n",
    "        # Convert the latest result to a DataFrame and print it\n",
    "        result_table = pd.DataFrame(table_rows, columns=['Variable', 'cu', 'co', 'Model', 'Pinball Loss', 'Best Params', 'delta C', 'sl'])\n",
    "        print(result_table)  # Print the updated results after each column is processed\n",
    "\n",
    "# Final result table after processing all combinations\n",
    "result_table = pd.DataFrame(table_rows, columns=['Variable', 'cu', 'co', 'Model', 'Pinball Loss', 'Best Params', 'delta C', 'sl'])\n",
    "\n",
    "# Define the folder where results will be saved\n",
    "results_folder = \"results\"\n",
    "\n",
    "# Check if the results folder exists, if not, create it\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "# Construct the filename using the format \"results_basic_Models_{dataset_name}.csv\"\n",
    "filename = os.path.join(results_folder, f\"results_basic_Models_{dataset_name}.csv\")\n",
    "\n",
    "# Save the result table to a CSV file in the \"results\" folder\n",
    "result_table.to_csv(filename, index=False)\n",
    "\n",
    "# Aggregate and save cross-validation results at the end of the entire workflow\n",
    "if globals.global_cv_results:\n",
    "    # Concatenate all cross-validation results into a single DataFrame\n",
    "    aggregated_cv_results_df = pd.concat(globals.global_cv_results, ignore_index=True)\n",
    "\n",
    "    # Save the aggregated results to a CSV file in the \"results\" folder\n",
    "    aggregated_cv_filename = os.path.join(results_folder, f\"cv_scores_basic_models_{dataset_name}.csv\")\n",
    "    aggregated_cv_results_df.to_csv(aggregated_cv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Filter out both 'SAA' and 'LinearRegression' models\n",
    "filtered_table = result_table[(~result_table['Model'].isin(['SAA', 'LR', 'MLP','LGBM'])) & (result_table['sl'] == 0.9)]\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the boxplot\n",
    "sns.boxplot(x='Model', y='delta C', data=filtered_table, showfliers=False, width=0.5, color='lightblue')\n",
    "\n",
    " #Add the stripplot to show the individual data points\n",
    "#sns.stripplot(x='Model', y='delta C', data=filtered_table, color='red', jitter=True, size=6, alpha=0.7)\n",
    "\n",
    "# Add the point plot to show CI based on SD without horizontal lines\n",
    "sns.pointplot(x=\"Model\", y=\"delta C\", data=filtered_table, ci='sd', color='blue', markers=\"o\", scale=0.7, linestyles=\"\")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Boxplot, Stripplot, and Pointplot (CI=SD) of Delta C for Each Model (Excluding SAA and LinearRegression)', fontsize=14)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.ylabel('Delta C', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process - DRF + Levelset Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "\n",
    "timeseries = True\n",
    "\n",
    "# Execution starts here\n",
    "combinations = [(1, 9)]\n",
    "table_rows = []\n",
    "random_state = 1\n",
    "drf_cv_results = []\n",
    "global_fold_scores = []\n",
    "\n",
    "# Iterate over combinations and process them directly\n",
    "for cu, co in combinations:\n",
    "    print(f\"Processing cu, co combination: cu={cu}, co={co}\")\n",
    "    tau = cu / (cu + co)\n",
    "    with threadpool_limits(limits=1):\n",
    "            for column in y_train.columns:\n",
    "                print(f\"Processing column: {column}\")\n",
    "\n",
    "                # Preprocess data\n",
    "                X_train_scaled, X_test_scaled, y_train_col, y_test_col, X_train_scaled_withID = preprocess_per_instance_singleID(\n",
    "                    column, X_train_features, X_test_features, y_train, y_test\n",
    "                )\n",
    "                create_cv_folds_singleID(X_train_scaled_withID)\n",
    "            \n",
    "\n",
    "                # SAA model evaluation\n",
    "                saa_model = SampleAverageApproximationNewsvendor(cu, co)\n",
    "                saa_pred = saa_model.fit(y_train_col).predict(X_test_scaled.shape[0])\n",
    "                saa_pinball_loss = pinball_loss(y_test_col.values.flatten(), saa_pred, tau)\n",
    "                append_result(table_rows, column, cu, co, 'SAA', saa_pinball_loss, 'N/A', np.nan, tau)\n",
    "\n",
    "            \n",
    "            \n",
    "                if timeseries:\n",
    "                    # Initialisiere LGBM und MLP-Modelle\n",
    "                    lgbm_model = LGBMRegressor(random_state=random_state, n_jobs=1, verbosity=-1)\n",
    "                    mlp_model = MLPRegressorWrapper(random_state=random_state, early_stopping=True)\n",
    "\n",
    "                    # LGBM-Modell mit GroupSplitting evaluieren\n",
    "                    lgbm_model_params = get_grid('LevelSetKDEx_groupsplit', X_train_scaled.shape[1])\n",
    "                    lgbm_model_evaluation = [\n",
    "                        ('LS_KDEx_LGBM', LevelSetKDEx(estimator=lgbm_model, binSize=100, weightsByDistance=False), lgbm_model_params)\n",
    "                    ]\n",
    "                    evaluate_and_append_models_singleID(lgbm_model_evaluation, X_train_scaled, X_test_scaled, y_train_col, y_test_col, saa_pinball_loss, tau, cu, co, column, table_rows, timeseries)\n",
    "\n",
    "                    # MLP-Modell mit GroupSplitting evaluieren\n",
    "                    mlp_model_params = get_grid('LevelSetKDEx_groupsplit', X_train_scaled.shape[1])\n",
    "                    mlp_model_evaluation = [\n",
    "                        ('LS_KDEx_MLP', LevelSetKDEx(estimator=mlp_model, binSize=100, weightsByDistance=False), mlp_model_params)\n",
    "                    ]\n",
    "                    evaluate_and_append_models_singleID(mlp_model_evaluation, X_train_scaled, X_test_scaled, y_train_col, y_test_col, saa_pinball_loss, tau, cu, co, column, table_rows, timeseries)\n",
    "\n",
    "\n",
    "                else:\n",
    "                    # Although the Wage data set is not a timeseries, it works similarly well on group timeseries splits. \n",
    "                    # To do this, we set shuffle = True beforehand in the preprocessing for train/test split. \n",
    "                    # Resulting in an mixed order of the train/test points, even if we order it by the \"Dayindex\" later in the CV splits.\n",
    "                    # saves the extra work and we can work the same split logic for all datasets\n",
    "                    print(\"Only time series Data\")\n",
    "\n",
    "                # DRF-Modell wird immer ausgeführt\n",
    "                drf_model = DRFWrapper(min_node_size=10, num_trees=100, num_threads=12)\n",
    "                drf_grid = get_grid('DRF', X_train_scaled.shape[1])\n",
    "                evaluate_and_append_models_singleID([('DRF', drf_model, drf_grid)], X_train_scaled, X_test_scaled, y_train_col, y_test_col, saa_pinball_loss, tau, cu, co, column, table_rows, timeseries)\n",
    "\n",
    "\n",
    "                # Print the table after evaluating each column\n",
    "                second_result_table = pd.DataFrame(table_rows, columns=['Variable', 'cu', 'co', 'Model', 'Pinball Loss', 'Best Params', 'delta C', 'sl'])\n",
    "                print(second_result_table.tail(5))  # Print the last 5 rows of the table after each column is processed\n",
    "\n",
    "\n",
    "# Define the folder where results will be saved\n",
    "results_folder = \"results\"\n",
    "\n",
    "# Check if the results folder exists, if not, create it\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "# Final result table after processing all combinations\n",
    "second_result_table = pd.DataFrame(table_rows, columns=['Variable', 'cu', 'co', 'Model', 'Pinball Loss', 'Best Params', 'delta C', 'sl'])\n",
    "\n",
    "\n",
    "# Construct the filename and save it in the \"results\" folder\n",
    "filename = os.path.join(results_folder, f\"results_LevelsetModels_{dataset_name}.csv\")\n",
    "second_result_table.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Results saved as {filename}\")\n",
    "\n",
    "# Aggregating fold-wise cross-validation results\n",
    "if global_fold_scores:  # No 'globals' function, just directly use 'global_fold_scores'\n",
    "    # Reset multi-index for all fold scores\n",
    "    global_fold_scores_flat = []\n",
    "    for fold_scores_df in global_fold_scores:\n",
    "        # Reset the multi-index so that the binSize and weightsByDistance become normal columns\n",
    "        flat_df = fold_scores_df.reset_index()\n",
    "        global_fold_scores_flat.append(flat_df)\n",
    "\n",
    "    # Concatenate all fold-wise cross-validation results into a single DataFrame\n",
    "    aggregated_fold_scores_df = pd.concat(global_fold_scores_flat, ignore_index=True)\n",
    "\n",
    "    # Save the aggregated results to a CSV file in the \"results\" folder\n",
    "    aggregated_fold_scores_filename = os.path.join(results_folder, f\"cv_scores_levelset_models_{dataset_name}.csv\")\n",
    "    aggregated_fold_scores_df.to_csv(aggregated_fold_scores_filename, index=False)\n",
    "\n",
    "    ### DRF DATA INSERTED INTO THE MAIN TABLE WHERE OTHER BAYES CVs ARE STORED\n",
    "    aggregated_drf_cv_results_df = pd.concat(drf_cv_results, ignore_index=True)\n",
    "\n",
    "    # Save the aggregated DRF results to a CSV file in the \"results\" folder\n",
    "    aggregated_cv_filename = os.path.join(results_folder, f\"cv_drf_scores_{dataset_name}.csv\")\n",
    "    aggregated_drf_cv_results_df.to_csv(aggregated_cv_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Filter out specific models and only include rows where 'sl' equals 0.9\n",
    "filtered_table = second_result_table[\n",
    "    (~second_result_table['Model'].isin(['SAA', 'LR', 'MLP', 'LGBM'])) & \n",
    "    (second_result_table['sl'] == 0.9)\n",
    "]\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the boxplot\n",
    "sns.boxplot(x='Model', y='delta C', data=filtered_table, showfliers=False, width=0.5, color='lightblue')\n",
    "\n",
    "# Add the point plot to show CI based on SD without horizontal lines\n",
    "sns.pointplot(x=\"Model\", y=\"delta C\", data=filtered_table, ci='sd', color='blue', markers=\"o\", scale=0.7, linestyles=\"\")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Boxplot and Pointplot (CI=SD) of Delta C for Each Model (Excluding SAA and LinearRegression)', fontsize=14)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.ylabel('Delta C', fontsize=12)\n",
    "\n",
    "# Show the plot with tight layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FULL Dataset Cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.shared_imports import *\n",
    "\n",
    "# Verify that the current working directory has changed\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Importiere alle Module\n",
    "from scripts.get_data import get_dataset_settings_alldata, preprocess_data_alldata\n",
    "from Wrapper.wrapper import DRFWrapper, MLPRegressorWrapper\n",
    "from scripts.utils import *\n",
    "from scripts.train_and_evaluate_alldata import (  \n",
    "    evaluate_and_append_models_alldata, create_cv_folds_alldata, preprocess_per_instance_alldata\n",
    ")\n",
    "from scripts.process_target import process_target_alldata\n",
    "\n",
    "import scripts.config as config\n",
    "from scripts.globals import global_fold_scores, global_cv_results, drf_cv_results\n",
    "\n",
    "# Lade alle Module neu\n",
    "importlib.reload(config)\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'  # OpenMP Threads auf 4 beschränken\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'  # Für OpenBLAS\n",
    "os.environ['MKL_NUM_THREADS'] = '1'  # Für Intel MKL (falls verwendet)\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'  # Für NumExpr\n",
    "os.environ['VECLIB_MAXIMUM_THREADS'] = '1'  # Für MacOS Accelerate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = config.dataset_name\n",
    "\n",
    "# Hole die Datei-ID für den gewählten Datensatz\n",
    "file_id = {\n",
    "    'subset_bakery': '1r_bDn9Z3Q_XgeTTkJL7352nUG3jkUM0z',\n",
    "    'yaz': '1xrY3Uv5F9F9ofgSM7dVoSK4bE0gPMg36',\n",
    "    'subset_m5': '1tCBaxOgE5HHllvLVeRC18zvALBz6B-6w',\n",
    "    'sid': '1J9bPCfeLDH-mbSnvTHRoCva7pl6cXD3_',\n",
    "    'subset_air': '1DMOaV92n3BFEGeCubaxEys2eLzg2Cic3',\n",
    "    \"copula\": '1H5wdJgmxdhbzeS17w0NkRlHRCESEAd-e',\n",
    "    'wage': '1bn7E7NOoRzE4NwXXs1MYhRSKZHC13qYU',\n",
    "}[config.dataset_name]\n",
    "\n",
    "\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "\n",
    "# Datei herunterladen\n",
    "output = f\"{dataset_name}.csv\"\n",
    "gdown.download(url, output, quiet=False)\n",
    "data = pd.read_csv(output)\n",
    "\n",
    "# Erstelle die Dataset-Einstellungen basierend auf den geladenen Daten\n",
    "settings = get_dataset_settings_alldata(data)[dataset_name]\n",
    "\n",
    "y, train_data, test_data, X_train_features, X_test_features, y_train, y_test, data, dataset_name  = preprocess_data_alldata(\n",
    "    data=data,\n",
    "    dataset_name=dataset_name,\n",
    "    bool_columns=settings['bool_columns'],\n",
    "    drop_columns=settings['drop_columns'],\n",
    "    drop_keywords=settings['drop_keywords'],\n",
    ")\n",
    "\n",
    "display(y_train.head(3))\n",
    "print(f\"Anzahl der Zeilen: {len(y_train)}\")\n",
    "print(\"Anzahl der targets:\", len(y_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDOP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Execution starts here\n",
    "combinations = [(9, 1), (7.5, 2.5), (5, 5), (2.5, 7.5), (1, 9)]\n",
    "table_rows = []\n",
    "random_state = 1\n",
    "global_cv_results = []\n",
    "\n",
    "# Initialize cvFolds\n",
    "cvFolds = None  # Initialization\n",
    "\n",
    "for cu, co in combinations:\n",
    "    print(f\"Processing cu, co combination: cu={cu}, co={co}\")\n",
    "    tau = cu / (cu + co)\n",
    "\n",
    "    # Parallelize column processing within each combination with n_jobs=4 to limit threads\n",
    "    column_results = Parallel(n_jobs=1)(\n",
    "        delayed(process_target_alldata)(column, cu, co, tau, y_train, X_train_features, X_test_features, y_test, random_state)\n",
    "        for column in y_train.columns\n",
    "    )\n",
    "\n",
    "    # Combine results from all columns and print after each column\n",
    "    for result in column_results:\n",
    "        table_rows.extend(result)\n",
    "        print(table_rows)\n",
    "        # Convert the latest result to a DataFrame and print it\n",
    "        result_table = pd.DataFrame(table_rows, columns=['Variable', 'cu', 'co', 'Model', 'Pinball Loss', 'Best Params', 'delta C', 'sl'])\n",
    "        print(result_table)  # Print the updated results after each column is processed\n",
    "\n",
    "# Final result table after processing all combinations\n",
    "result_table = pd.DataFrame(table_rows, columns=['Variable', 'cu', 'co', 'Model', 'Pinball Loss', 'Best Params', 'delta C', 'sl'])\n",
    "\n",
    "# Construct the filename using the format \"results_basicModels_{dataset_name}.csv\"\n",
    "filename = f\"FULLDATASET_results_basic_Models_{dataset_name}.csv\"\n",
    "result_table.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Results saved as {filename}\")\n",
    "\n",
    "# Aggregate and save cross-validation results at the end of the entire workflow\n",
    "if global_cv_results:\n",
    "    # Concatenate all cross-validation results into a single DataFrame\n",
    "    aggregated_cv_results_df = pd.concat(global_cv_results, ignore_index=True)\n",
    "\n",
    "    # Print a summary of the aggregated cross-validation data to verify it looks correct\n",
    "    print(\"Aggregated cross-validation results sample:\")\n",
    "    print(aggregated_cv_results_df.head(5))  # Print the first 5 rows as a sample\n",
    "\n",
    "    # Save the aggregated results to a CSV file\n",
    "    aggregated_cv_filename = f\"FULLDATASET_cv_scores_basic_models_{dataset_name}.csv\"\n",
    "    aggregated_cv_results_df.to_csv(aggregated_cv_filename, index=False)\n",
    "    print(f\"Aggregated cross-validation results saved as {aggregated_cv_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRF+Leveset Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = True\n",
    "import scripts.config as config\n",
    "from scripts.config import *\n",
    "importlib.reload(config)\n",
    "\n",
    "print(n_jobs)\n",
    "\n",
    "# Execution starts here\n",
    "combinations = [(9, 1), (7.5, 2.5), (5, 5), (2.5, 7.5), (1, 9)]\n",
    "\n",
    "table_rows = []\n",
    "random_state = 1\n",
    "drf_cv_results = []\n",
    "global_fold_scores = []\n",
    "\n",
    "# Iterate over combinations and process them directly\n",
    "for cu, co in combinations:\n",
    "    print(f\"Processing cu, co combination: cu={cu}, co={co}\")\n",
    "    tau = cu / (cu + co)\n",
    "    with threadpool_limits(limits=1):\n",
    "            for column in y_train.columns:\n",
    "                print(f\"Processing column: {column}\")\n",
    "\n",
    "                              # Preprocess data\n",
    "                X_train_scaled, X_test_scaled, y_train_col, y_test_col, X_train_scaled_withID, X_test_scaled_withID = preprocess_per_instance_alldata(\n",
    "                    column, X_train_features, X_test_features, y_train, y_test\n",
    "                )\n",
    "\n",
    "                create_cv_folds_alldata(X_train_scaled_withID)\n",
    "                \n",
    "                # SAA model\n",
    "                saa_model = SampleAverageApproximationNewsvendor(cu, co)\n",
    "                saa_pred = saa_model.fit(y_train_col).predict(X_test_scaled.shape[0])\n",
    "\n",
    "\n",
    "                # Ensure id_for_CV, y_true, and y_pred are 1-D arrays\n",
    "                id_for_CV = X_test_scaled_withID['id_for_CV'].values.flatten()\n",
    "                y_true = y_test_col.values.flatten()\n",
    "                y_pred = saa_pred.flatten()  # Flatten y_pred to ensure it's 1-D\n",
    "\n",
    "                # Create DataFrame for SAA predictions\n",
    "                saa_predictions_df = pd.DataFrame({\n",
    "                    'id_for_CV': id_for_CV,\n",
    "                    'y_true': y_true,\n",
    "                    'y_pred': y_pred  # Use the flattened y_pred here\n",
    "                })\n",
    "\n",
    "                saa_pinball_losses_per_id = {}\n",
    "                grouped_saa = saa_predictions_df.groupby('id_for_CV')\n",
    "                for id_val, group in grouped_saa:\n",
    "                    y_true_id = group['y_true'].values\n",
    "                    y_pred_id = group['y_pred'].values\n",
    "                    pinball_loss_id = pinball_loss(y_true_id, y_pred_id, tau)\n",
    "                    saa_pinball_losses_per_id[id_val] = pinball_loss_id\n",
    "                    append_result(table_rows, id_val, cu, co, 'SAA', pinball_loss_id, 'N/A', np.nan, tau)\n",
    "\n",
    "                n_features = X_train_scaled.shape[1]\n",
    "\n",
    "                drf_model = DRFWrapper(min_node_size=10, num_trees=100, num_threads=2)\n",
    "                drf_grid = get_grid('DRF', X_train_scaled.shape[1])\n",
    "                \n",
    "                print(f\"Length of X_train_scaled: {len(X_train_scaled)}\")\n",
    "                print(f\"Length of X_test_scaled: {len(X_test_scaled)}\")\n",
    "                evaluate_and_append_models_alldata([('DRF', drf_model, drf_grid)], X_train_scaled, X_test_scaled, y_train_col, y_test_col, saa_pinball_losses_per_id, tau, cu, co, column, table_rows, timeseries, X_test_scaled_withID)\n",
    "\n",
    "\n",
    "            \n",
    "                if timeseries:\n",
    "                    # Initialisiere LGBM und MLP-Modelle\n",
    "                    lgbm_model = LGBMRegressor(random_state=random_state, n_jobs=n_jobs, verbosity=-1)\n",
    "                    mlp_model = MLPRegressorWrapper(random_state=random_state, early_stopping=True)\n",
    "\n",
    "                    # LGBM-Modell mit GroupSplitting evaluieren\n",
    "                    lgbm_model_params = get_grid('LevelSetKDEx_groupsplit', X_train_scaled.shape[1])\n",
    "                    print(lgbm_model_params)\n",
    "\n",
    "                    lgbm_model_evaluation = [\n",
    "                        ('LS_KDEx_LGBM', LevelSetKDEx(estimator=lgbm_model, binSize=100, weightsByDistance=False), lgbm_model_params)\n",
    "                    ]\n",
    "                    evaluate_and_append_models_alldata(lgbm_model_evaluation, X_train_scaled, X_test_scaled,\n",
    "                                       y_train_col, y_test_col, saa_pinball_losses_per_id,\n",
    "                                       tau, cu, co, column, table_rows, timeseries, X_test_scaled_withID)\n",
    "\n",
    "                    # MLP-Modell mit GroupSplitting evaluieren\n",
    "                    mlp_model_params = get_grid('LevelSetKDEx_groupsplit', X_train_scaled.shape[1])\n",
    "                    mlp_model_evaluation = [\n",
    "                        ('LS_KDEx_MLP', LevelSetKDEx(estimator=mlp_model, binSize=100, weightsByDistance=False), mlp_model_params)\n",
    "                    ]\n",
    "                    evaluate_and_append_models_alldata(mlp_model_evaluation, X_train_scaled, X_test_scaled,\n",
    "                                       y_train_col, y_test_col, saa_pinball_losses_per_id,\n",
    "                                       tau, cu, co, column, table_rows, timeseries, X_test_scaled_withID)\n",
    "\n",
    "\n",
    "                else:\n",
    "                    # Although the Wage data set is not a timeseries, it works similarly well on group timeseries splits. \n",
    "                    # To do this, we set shuffle = True once in the train/test split. \n",
    "                    # Resulting in an mixed order of the train/test points, even if we order it by the Index.\n",
    "                    print(\"Only time series Data\")\n",
    "\n",
    "                # Print the table after evaluating each column\n",
    "                second_result_table = pd.DataFrame(table_rows, columns=['Variable', 'cu', 'co', 'Model', 'Pinball Loss', 'Best Params', 'delta C', 'sl'])\n",
    "                print(second_result_table.tail(5))  # Print the last 5 rows of the table after each column is processed\n",
    "\n",
    "\n",
    "# Final result table after processing all combinations\n",
    "second_result_table = pd.DataFrame(table_rows, columns=['Variable', 'cu', 'co', 'Model', 'Pinball Loss', 'Best Params', 'delta C', 'sl'])\n",
    "filename = f\"FULLDATASET_results_LevelsetModels_{dataset_name}.csv\"\n",
    "\n",
    "\n",
    "second_result_table.to_csv(filename, index=False)\n",
    "# Define the folder where results will be saved\n",
    "results_folder = \"results\"\n",
    "\n",
    "from scripts.globals import global_fold_scores, global_cv_results, drf_cv_results\n",
    "\n",
    "\n",
    "# Construct the filename and save it in the \"results\" folder\n",
    "filename = os.path.join(results_folder, f\"FULLDATASET_results_LevelsetModels_{dataset_name}.csv\")\n",
    "second_result_table.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Results saved as {filename}\")\n",
    "\n",
    "# Aggregating fold-wise cross-validation results\n",
    "if global_fold_scores:  # No 'globals' function, just directly use 'global_fold_scores'\n",
    "    # Reset multi-index for all fold scores\n",
    "    global_fold_scores_flat = []\n",
    "    for fold_scores_df in global_fold_scores:\n",
    "        # Reset the multi-index so that the binSize and weightsByDistance become normal columns\n",
    "        flat_df = fold_scores_df.reset_index()\n",
    "        global_fold_scores_flat.append(flat_df)\n",
    "\n",
    "    # Concatenate all fold-wise cross-validation results into a single DataFrame\n",
    "    aggregated_fold_scores_df = pd.concat(global_fold_scores_flat, ignore_index=True)\n",
    "\n",
    "    # Save the aggregated results to a CSV file in the \"results\" folder\n",
    "    aggregated_fold_scores_filename = os.path.join(results_folder, f\"FULLDATASET_cv_scores_levelset_models_{dataset_name}.csv\")\n",
    "    aggregated_fold_scores_df.to_csv(aggregated_fold_scores_filename, index=False)\n",
    "\n",
    "    ### DRF DATA INSERTED INTO THE MAIN TABLE WHERE OTHER BAYES CVs ARE STORED\n",
    "    aggregated_drf_cv_results_df = pd.concat(drf_cv_results, ignore_index=True)\n",
    "\n",
    "    # Save the aggregated DRF results to a CSV file in the \"results\" folder\n",
    "    aggregated_cv_filename = os.path.join(results_folder, f\"cv_drf_scores_{dataset_name}.csv\")\n",
    "    aggregated_drf_cv_results_df.to_csv(aggregated_cv_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter die Tabelle, um nur die Zeilen mit dem Modell \"SAA\" anzuzeigen\n",
    "saa_results = result_table[result_table['Model'] == 'SAA']\n",
    "\n",
    "# Zeige die ersten 20 Zeilen der gefilterten Tabelle an\n",
    "print(saa_results.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
