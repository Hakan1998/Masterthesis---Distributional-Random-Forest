{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main\n"
     ]
    }
   ],
   "source": [
    "print(\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 15:51:11.251657: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-10 15:51:11.257507: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-10 15:51:11.329769: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-10 15:51:11.336128: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-10 15:51:13.491131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /root/WorkingFolder\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import gdown\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.rinterface import RRuntimeWarning\n",
    "from rpy2.rinterface_lib.callbacks import logger as rpy2_logger\n",
    "from pulp import LpSolverDefault\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "# Custom or external package imports\n",
    "from ddop2.newsvendor import (\n",
    "    DecisionTreeWeightedNewsvendor, KNeighborsWeightedNewsvendor, \n",
    "    SampleAverageApproximationNewsvendor, DeepLearningNewsvendor, \n",
    "    RandomForestWeightedNewsvendor, GaussianWeightedNewsvendor, \n",
    "    LinearRegressionNewsvendor\n",
    ")\n",
    "from drf import drf\n",
    "from dddex.levelSetKDEx_univariate import LevelSetKDEx\n",
    "from dddex.loadData import loadDataYaz\n",
    "from dddex.crossValidation import QuantileCrossValidation, groupedTimeSeriesSplit\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from threadpoolctl import threadpool_limits  # Importiere threadpool_limits\n",
    "\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_colwidth', None)  # Show full column width\n",
    "pd.set_option('display.max_rows', 10)  # Limit the number of displayed rows\n",
    "pd.set_option('display.width', 1000)  # Set high enough width to show all columns in a line\n",
    "\n",
    "# Suppress warnings and logging\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress all Python warnings\n",
    "rpy2_logger.setLevel(logging.CRITICAL)  # Only show critical messages from R\n",
    "\n",
    "# Set R options to suppress warnings and messages\n",
    "ro.r('while (sink.number() > 0) sink(NULL)')  # Close open sinks to avoid \"sink stack full\" errors\n",
    "ro.r('options(warn=-1)')  # Disable all warnings in R\n",
    "ro.r('suppressMessages(suppressWarnings(library(\"drf\")))')  # Suppress R package messages and warnings\n",
    "\n",
    "# Set environment variables for R libraries\n",
    "os.environ['R_LIBS_USER'] = '/usr/lib/R/site-library'\n",
    "os.environ['R_HOME'] = '/usr/lib/R'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Set random seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "# Deactivate CBC Solver output\n",
    "LpSolverDefault.msg = False  # Deactivates the CBC Solver output\n",
    "\n",
    "# Verify that the current working directory has changed\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'scripts.config' from '/root/WorkingFolder/scripts/config.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "# Importiere alle Module\n",
    "from scripts.get_data import get_dataset_settings, preprocess_data\n",
    "from Wrapper.wrapper import DRFWrapper, MLPRegressorWrapper, LevelSetKDExWrapper\n",
    "from scripts.cv_and_evaluation import (\n",
    "    pinball_loss, pinball_loss_scorer, preprocess_per_instance, \n",
    "    train_and_evaluate_model, calculate_n_iter, bayesian_search_model, \n",
    "    preprocess_per_instance, append_result, evaluate_and_append_models, create_cv_folds\n",
    ")\n",
    "from scripts.process_target import process_column\n",
    "from scripts.get_grids import get_grid\n",
    "import scripts.config as config\n",
    "\n",
    "# Lade alle Module neu\n",
    "importlib.reload(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set configurations in config.py file before we start process\n",
    "\n",
    "--> set dataset_name before in config file\n",
    "\n",
    "--> set levelset_calcuations to False if we do the basic models calcuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset_name \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39mdataset_name\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Hole die Datei-ID für den gewählten Datensatz\u001b[39;00m\n\u001b[1;32m      4\u001b[0m file_id \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbakery\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1r_bDn9Z3Q_XgeTTkJL7352nUG3jkUM0z\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myaz\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1xrY3Uv5F9F9ofgSM7dVoSK4bE0gPMg36\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwage\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1bn7E7NOoRzE4NwXXs1MYhRSKZHC13qYU\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m }[config\u001b[38;5;241m.\u001b[39mdataset_name]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_name = config.dataset_name\n",
    "\n",
    "# Hole die Datei-ID für den gewählten Datensatz\n",
    "file_id = {\n",
    "    'bakery': '1r_bDn9Z3Q_XgeTTkJL7352nUG3jkUM0z',\n",
    "    'yaz': '1xrY3Uv5F9F9ofgSM7dVoSK4bE0gPMg36',\n",
    "    'm5': '1tCBaxOgE5HHllvLVeRC18zvALBz6B-6w',\n",
    "    'sid': '1J9bPCfeLDH-mbSnvTHRoCva7pl6cXD3_',\n",
    "    'air': '1SKPpNxulcusNTjRwCC0p3C_XW7aNBNJZ',\n",
    "    \"copula\": '1H5wdJgmxdhbzeS17w0NkRlHRCESEAd-e',\n",
    "    'wage': '1bn7E7NOoRzE4NwXXs1MYhRSKZHC13qYU',\n",
    "}[config.dataset_name]\n",
    "\n",
    "\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "\n",
    "# Datei herunterladen\n",
    "output = f\"{dataset_name}.csv\"\n",
    "gdown.download(url, output, quiet=False)\n",
    "data = pd.read_csv(output)\n",
    "\n",
    "# Erstelle die Dataset-Einstellungen basierend auf den geladenen Daten\n",
    "settings = get_dataset_settings(data)[dataset_name]\n",
    "\n",
    "y, train_data, test_data, X_train_features, X_test_features, y_train, y_test = preprocess_data(\n",
    "    data, settings['backscaling_columns'], settings['bool_columns'], settings['drop_columns'])\n",
    "\n",
    "\n",
    "display(X_train_features.head(30))\n",
    "display(y_train.head(3))\n",
    "print(f\"Anzahl der Zeilen: {len(y_train)}\")\n",
    "print(\"Anzahl der targets:\", len(y_train.columns))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### thread settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OMP_NUM_THREADS'] = '1'  # OpenMP Threads auf 4 beschränken\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'  # Für OpenBLAS\n",
    "os.environ['MKL_NUM_THREADS'] = '1'  # Für Intel MKL (falls verwendet)\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'  # Für NumExpr\n",
    "os.environ['VECLIB_MAXIMUM_THREADS'] = '1'  # Für MacOS Accelerate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process - DDOP Models + Levelset Estimator Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(\u001b[43mconfig\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Execution starts here\n",
    "combinations = [(9, 1), (7.5, 2.5), (5, 5), (2.5, 7.5), (1, 9)]\n",
    "table_rows = []\n",
    "random_state = 42\n",
    "\n",
    "# Initialize cvFolds\n",
    "cvFolds = None  # Initialization\n",
    "\n",
    "\n",
    "import scripts.globals as globals  # Import the globals module\n",
    "\n",
    "for cu, co in combinations:\n",
    "    print(f\"Processing cu, co combination: cu={cu}, co={co}\")\n",
    "    tau = cu / (cu + co)\n",
    "\n",
    "    # Parallelize column processing within each combination with n_jobs=4 to limit threads\n",
    "    column_results = Parallel(n_jobs=1)(  \n",
    "        delayed(process_column)(column, cu, co, tau, y_train, X_train_features, X_test_features, y_test, random_state)\n",
    "        for column in y_train.columns\n",
    "    )\n",
    "\n",
    "    # Combine results from all columns and print after each column\n",
    "    for result in column_results:\n",
    "        table_rows.extend(result)\n",
    "        print(table_rows)\n",
    "        # Convert the latest result to a DataFrame and print it\n",
    "        result_table = pd.DataFrame(table_rows, columns=['Variable', 'cu', 'co', 'Model', 'Pinball Loss', 'Best Params', 'delta C', 'sl'])\n",
    "        print(result_table)  # Print the updated results after each column is processed\n",
    "\n",
    "# Final result table after processing all combinations\n",
    "result_table = pd.DataFrame(table_rows, columns=['Variable', 'cu', 'co', 'Model', 'Pinball Loss', 'Best Params', 'delta C', 'sl'])\n",
    "\n",
    "# Define the folder where results will be saved\n",
    "results_folder = \"results\"\n",
    "\n",
    "# Check if the results folder exists, if not, create it\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "# Construct the filename using the format \"results_basic_Models_{dataset_name}.csv\"\n",
    "filename = os.path.join(results_folder, f\"results_basic_Models_{dataset_name}.csv\")\n",
    "\n",
    "# Save the result table to a CSV file in the \"results\" folder\n",
    "result_table.to_csv(filename, index=False)\n",
    "\n",
    "# Aggregate and save cross-validation results at the end of the entire workflow\n",
    "if globals.global_cv_results:\n",
    "    # Concatenate all cross-validation results into a single DataFrame\n",
    "    aggregated_cv_results_df = pd.concat(globals.global_cv_results, ignore_index=True)\n",
    "\n",
    "    # Save the aggregated results to a CSV file in the \"results\" folder\n",
    "    aggregated_cv_filename = os.path.join(results_folder, f\"cv_scores_basic_models_{dataset_name}.csv\")\n",
    "    aggregated_cv_results_df.to_csv(aggregated_cv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Filter out both 'SAA' and 'LinearRegression' models\n",
    "filtered_table = result_table[(~result_table['Model'].isin(['SAA', 'LR', 'MLP','LGBM'])) & (result_table['sl'] == 0.9)]\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the boxplot\n",
    "sns.boxplot(x='Model', y='delta C', data=filtered_table, showfliers=False, width=0.5, color='lightblue')\n",
    "\n",
    " #Add the stripplot to show the individual data points\n",
    "#sns.stripplot(x='Model', y='delta C', data=filtered_table, color='red', jitter=True, size=6, alpha=0.7)\n",
    "\n",
    "# Add the point plot to show CI based on SD without horizontal lines\n",
    "sns.pointplot(x=\"Model\", y=\"delta C\", data=filtered_table, ci='sd', color='blue', markers=\"o\", scale=0.7, linestyles=\"\")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Boxplot, Stripplot, and Pointplot (CI=SD) of Delta C for Each Model (Excluding SAA and LinearRegression)', fontsize=14)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.ylabel('Delta C', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process - DRF + Levelset Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from collections import OrderedDict\n",
    "\n",
    "timeseries = True\n",
    "\n",
    "# Execution starts here\n",
    "combinations = [(1, 9)]\n",
    "table_rows = []\n",
    "random_state = 1\n",
    "drf_cv_results = []\n",
    "global_fold_scores = []\n",
    "\n",
    "# Iterate over combinations and process them directly\n",
    "for cu, co in combinations:\n",
    "    print(f\"Processing cu, co combination: cu={cu}, co={co}\")\n",
    "    tau = cu / (cu + co)\n",
    "    with threadpool_limits(limits=1):\n",
    "            for column in y_train.columns:\n",
    "                print(f\"Processing column: {column}\")\n",
    "\n",
    "                # Preprocess data\n",
    "                X_train_scaled, X_test_scaled, y_train_col, y_test_col, X_train_scaled_withID = preprocess_per_instance(\n",
    "                    column, X_train_features, X_test_features, y_train, y_test\n",
    "                )\n",
    "                create_cv_folds(X_train_scaled_withID)\n",
    "                \n",
    "                # SAA model evaluation\n",
    "                saa_model = SampleAverageApproximationNewsvendor(cu, co)\n",
    "                saa_pred = saa_model.fit(y_train_col).predict(X_test_scaled.shape[0])\n",
    "                saa_pinball_loss = pinball_loss(y_test_col.values.flatten(), saa_pred, tau)\n",
    "                append_result(table_rows, column, cu, co, 'SAA', saa_pinball_loss, 'N/A', np.nan, tau)\n",
    "\n",
    "            \n",
    "            \n",
    "                if timeseries:\n",
    "                    # Initialisiere LGBM und MLP-Modelle\n",
    "                    lgbm_model = LGBMRegressor(random_state=random_state, n_jobs=1, verbosity=-1)\n",
    "                    mlp_model = MLPRegressorWrapper(random_state=random_state, early_stopping=True)\n",
    "\n",
    "                    # LGBM-Modell mit GroupSplitting evaluieren\n",
    "                    lgbm_model_params = get_grid('LevelSetKDEx_groupsplit', X_train_scaled.shape[1])\n",
    "                    lgbm_model_evaluation = [\n",
    "                        ('LS_KDEx_LGBM', LevelSetKDEx(estimator=lgbm_model, binSize=100, weightsByDistance=False), lgbm_model_params)\n",
    "                    ]\n",
    "                    evaluate_and_append_models(lgbm_model_evaluation, X_train_scaled, X_test_scaled, y_train_col, y_test_col, saa_pinball_loss, tau, cu, co, column, table_rows, timeseries)\n",
    "\n",
    "                    # MLP-Modell mit GroupSplitting evaluieren\n",
    "                    mlp_model_params = get_grid('LevelSetKDEx_groupsplit', X_train_scaled.shape[1])\n",
    "                    mlp_model_evaluation = [\n",
    "                        ('LS_KDEx_MLP', LevelSetKDEx(estimator=mlp_model, binSize=100, weightsByDistance=False), mlp_model_params)\n",
    "                    ]\n",
    "                    evaluate_and_append_models(mlp_model_evaluation, X_train_scaled, X_test_scaled, y_train_col, y_test_col, saa_pinball_loss, tau, cu, co, column, table_rows, timeseries)\n",
    "\n",
    "\n",
    "                else:\n",
    "                    # Although the Wage data set is not a timeseries, it works similarly well on group timeseries splits. \n",
    "                    # To do this, we set shuffle = True beforehand in the preprocessing for train/test split. \n",
    "                    # Resulting in an mixed order of the train/test points, even if we order it by the \"Dayindex\" later in the CV splits.\n",
    "                    # saves the extra work and we can work the same split logic for all datasets\n",
    "                    print(\"Only time series Data\")\n",
    "\n",
    "                # DRF-Modell wird immer ausgeführt\n",
    "                drf_model = DRFWrapper(min_node_size=10, num_trees=100, num_threads=12)\n",
    "                drf_grid = get_grid('DRF', X_train_scaled.shape[1])\n",
    "                evaluate_and_append_models([('DRF', drf_model, drf_grid)], X_train_scaled, X_test_scaled, y_train_col, y_test_col, saa_pinball_loss, tau, cu, co, column, table_rows, timeseries)\n",
    "\n",
    "\n",
    "                # Print the table after evaluating each column\n",
    "                second_result_table = pd.DataFrame(table_rows, columns=['Variable', 'cu', 'co', 'Model', 'Pinball Loss', 'Best Params', 'delta C', 'sl'])\n",
    "                print(second_result_table.tail(5))  # Print the last 5 rows of the table after each column is processed\n",
    "\n",
    "\n",
    "# Define the folder where results will be saved\n",
    "results_folder = \"results\"\n",
    "\n",
    "# Check if the results folder exists, if not, create it\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "# Final result table after processing all combinations\n",
    "second_result_table = pd.DataFrame(table_rows, columns=['Variable', 'cu', 'co', 'Model', 'Pinball Loss', 'Best Params', 'delta C', 'sl'])\n",
    "\n",
    "from scripts.globals import global_fold_scores, global_cv_results, drf_cv_results\n",
    "\n",
    "\n",
    "# Construct the filename and save it in the \"results\" folder\n",
    "filename = os.path.join(results_folder, f\"results_LevelsetModels_{dataset_name}.csv\")\n",
    "second_result_table.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Results saved as {filename}\")\n",
    "\n",
    "# Aggregating fold-wise cross-validation results\n",
    "if global_fold_scores:  # No 'globals' function, just directly use 'global_fold_scores'\n",
    "    # Reset multi-index for all fold scores\n",
    "    global_fold_scores_flat = []\n",
    "    for fold_scores_df in global_fold_scores:\n",
    "        # Reset the multi-index so that the binSize and weightsByDistance become normal columns\n",
    "        flat_df = fold_scores_df.reset_index()\n",
    "        global_fold_scores_flat.append(flat_df)\n",
    "\n",
    "    # Concatenate all fold-wise cross-validation results into a single DataFrame\n",
    "    aggregated_fold_scores_df = pd.concat(global_fold_scores_flat, ignore_index=True)\n",
    "\n",
    "    # Save the aggregated results to a CSV file in the \"results\" folder\n",
    "    aggregated_fold_scores_filename = os.path.join(results_folder, f\"cv_scores_levelset_models_{dataset_name}.csv\")\n",
    "    aggregated_fold_scores_df.to_csv(aggregated_fold_scores_filename, index=False)\n",
    "\n",
    "    ### DRF DATA INSERTED INTO THE MAIN TABLE WHERE OTHER BAYES CVs ARE STORED\n",
    "    aggregated_drf_cv_results_df = pd.concat(drf_cv_results, ignore_index=True)\n",
    "\n",
    "    # Save the aggregated DRF results to a CSV file in the \"results\" folder\n",
    "    aggregated_cv_filename = os.path.join(results_folder, f\"cv_drf_scores_{dataset_name}.csv\")\n",
    "    aggregated_drf_cv_results_df.to_csv(aggregated_cv_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Filter out specific models and only include rows where 'sl' equals 0.9\n",
    "filtered_table = second_result_table[\n",
    "    (~second_result_table['Model'].isin(['SAA', 'LR', 'MLP', 'LGBM'])) & \n",
    "    (second_result_table['sl'] == 0.9)\n",
    "]\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the boxplot\n",
    "sns.boxplot(x='Model', y='delta C', data=filtered_table, showfliers=False, width=0.5, color='lightblue')\n",
    "\n",
    "# Add the point plot to show CI based on SD without horizontal lines\n",
    "sns.pointplot(x=\"Model\", y=\"delta C\", data=filtered_table, ci='sd', color='blue', markers=\"o\", scale=0.7, linestyles=\"\")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Boxplot and Pointplot (CI=SD) of Delta C for Each Model (Excluding SAA and LinearRegression)', fontsize=14)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.ylabel('Delta C', fontsize=12)\n",
    "\n",
    "# Show the plot with tight layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FULL Dataset Cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.full_dataset_training import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1xrY3Uv5F9F9ofgSM7dVoSK4bE0gPMg36\n",
      "To: /root/WorkingFolder/yaz.csv\n",
      "100%|██████████| 3.13M/3.13M [00:00<00:00, 4.50MB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>dayIndex</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>weekend</th>\n",
       "      <th>wind</th>\n",
       "      <th>clouds</th>\n",
       "      <th>rain</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>label</th>\n",
       "      <th>scalingValue</th>\n",
       "      <th>demand__sum_values_7</th>\n",
       "      <th>demand__median_7</th>\n",
       "      <th>demand__mean_7</th>\n",
       "      <th>demand__standard_deviation_7</th>\n",
       "      <th>demand__variance_7</th>\n",
       "      <th>demand__root_mean_square_7</th>\n",
       "      <th>demand__maximum_7</th>\n",
       "      <th>demand__absolute_maximum_7</th>\n",
       "      <th>demand__minimum_7</th>\n",
       "      <th>demand__sum_values_14</th>\n",
       "      <th>demand__median_14</th>\n",
       "      <th>demand__mean_14</th>\n",
       "      <th>demand__standard_deviation_14</th>\n",
       "      <th>demand__variance_14</th>\n",
       "      <th>demand__root_mean_square_14</th>\n",
       "      <th>demand__maximum_14</th>\n",
       "      <th>demand__absolute_maximum_14</th>\n",
       "      <th>demand__minimum_14</th>\n",
       "      <th>demand__sum_values_28</th>\n",
       "      <th>demand__median_28</th>\n",
       "      <th>demand__mean_28</th>\n",
       "      <th>demand__standard_deviation_28</th>\n",
       "      <th>demand__variance_28</th>\n",
       "      <th>demand__root_mean_square_28</th>\n",
       "      <th>demand__maximum_28</th>\n",
       "      <th>demand__absolute_maximum_28</th>\n",
       "      <th>demand__minimum_28</th>\n",
       "      <th>demand</th>\n",
       "      <th>weekday_FRI</th>\n",
       "      <th>weekday_MON</th>\n",
       "      <th>weekday_SAT</th>\n",
       "      <th>weekday_SUN</th>\n",
       "      <th>weekday_THU</th>\n",
       "      <th>weekday_TUE</th>\n",
       "      <th>weekday_WED</th>\n",
       "      <th>month_APR</th>\n",
       "      <th>month_AUG</th>\n",
       "      <th>month_DEC</th>\n",
       "      <th>month_FEB</th>\n",
       "      <th>month_JAN</th>\n",
       "      <th>month_JUL</th>\n",
       "      <th>month_JUN</th>\n",
       "      <th>month_MAR</th>\n",
       "      <th>month_MAY</th>\n",
       "      <th>month_NOV</th>\n",
       "      <th>month_OCT</th>\n",
       "      <th>month_SEP</th>\n",
       "      <th>year_2013</th>\n",
       "      <th>year_2014</th>\n",
       "      <th>year_2015</th>\n",
       "      <th>item_calamari</th>\n",
       "      <th>item_chicken</th>\n",
       "      <th>item_fish</th>\n",
       "      <th>item_koefte</th>\n",
       "      <th>item_lamb</th>\n",
       "      <th>item_shrimp</th>\n",
       "      <th>item_steak</th>\n",
       "      <th>id_for_CV</th>\n",
       "      <th>dummyID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.052372</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.206743</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.070508</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>0.231023</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.12</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.080445</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.224881</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>calamari</td>\n",
       "      <td>dummyID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>train</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.087412</td>\n",
       "      <td>0.007641</td>\n",
       "      <td>0.192428</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.088156</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>0.218567</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.64</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.201429</td>\n",
       "      <td>0.089111</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.220260</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>calamari</td>\n",
       "      <td>dummyID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>train</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.291429</td>\n",
       "      <td>0.302156</td>\n",
       "      <td>0.091298</td>\n",
       "      <td>0.419796</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.220889</td>\n",
       "      <td>0.048792</td>\n",
       "      <td>0.328286</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.225714</td>\n",
       "      <td>0.172118</td>\n",
       "      <td>0.029624</td>\n",
       "      <td>0.283851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>calamari</td>\n",
       "      <td>dummyID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>train</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.262857</td>\n",
       "      <td>0.307511</td>\n",
       "      <td>0.094563</td>\n",
       "      <td>0.404546</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.234286</td>\n",
       "      <td>0.223150</td>\n",
       "      <td>0.049796</td>\n",
       "      <td>0.323552</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.221429</td>\n",
       "      <td>0.173199</td>\n",
       "      <td>0.029998</td>\n",
       "      <td>0.281120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>calamari</td>\n",
       "      <td>dummyID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>314.0</td>\n",
       "      <td>train</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.234286</td>\n",
       "      <td>0.321019</td>\n",
       "      <td>0.103053</td>\n",
       "      <td>0.397420</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.231146</td>\n",
       "      <td>0.053429</td>\n",
       "      <td>0.319106</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.215714</td>\n",
       "      <td>0.177712</td>\n",
       "      <td>0.031582</td>\n",
       "      <td>0.279489</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>calamari</td>\n",
       "      <td>dummyID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>train</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.194286</td>\n",
       "      <td>0.044994</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.199428</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.168571</td>\n",
       "      <td>0.064460</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>0.180476</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.197143</td>\n",
       "      <td>0.174333</td>\n",
       "      <td>0.030392</td>\n",
       "      <td>0.263168</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>calamari</td>\n",
       "      <td>dummyID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>train</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.194286</td>\n",
       "      <td>0.044994</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.199428</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.174286</td>\n",
       "      <td>0.059727</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.184236</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5.48</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.195714</td>\n",
       "      <td>0.174467</td>\n",
       "      <td>0.030439</td>\n",
       "      <td>0.262189</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>calamari</td>\n",
       "      <td>dummyID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.069985</td>\n",
       "      <td>0.004898</td>\n",
       "      <td>0.185164</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.165714</td>\n",
       "      <td>0.069046</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>0.179523</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5.36</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.191429</td>\n",
       "      <td>0.176751</td>\n",
       "      <td>0.031241</td>\n",
       "      <td>0.260549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>calamari</td>\n",
       "      <td>dummyID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.154286</td>\n",
       "      <td>0.054210</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.163532</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.168571</td>\n",
       "      <td>0.067914</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>0.181738</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5.36</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.191429</td>\n",
       "      <td>0.176751</td>\n",
       "      <td>0.031241</td>\n",
       "      <td>0.260549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>calamari</td>\n",
       "      <td>dummyID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>train</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.056569</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.169706</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.162857</td>\n",
       "      <td>0.061345</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.174028</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5.56</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.198571</td>\n",
       "      <td>0.172869</td>\n",
       "      <td>0.029884</td>\n",
       "      <td>0.263276</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>calamari</td>\n",
       "      <td>dummyID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  dayIndex  is_holiday  is_closed  weekend  wind  clouds  rain  sunshine  label  scalingValue  demand__sum_values_7  demand__median_7  demand__mean_7  demand__standard_deviation_7  demand__variance_7  demand__root_mean_square_7  demand__maximum_7  demand__absolute_maximum_7  demand__minimum_7  demand__sum_values_14  demand__median_14  demand__mean_14  demand__standard_deviation_14  demand__variance_14  demand__root_mean_square_14  demand__maximum_14  demand__absolute_maximum_14  demand__minimum_14  demand__sum_values_28  demand__median_28  demand__mean_28  demand__standard_deviation_28  demand__variance_28  demand__root_mean_square_28  demand__maximum_28  demand__absolute_maximum_28  demand__minimum_28  demand  weekday_FRI  weekday_MON  weekday_SAT  weekday_SUN  weekday_THU  weekday_TUE  weekday_WED  month_APR  month_AUG  month_DEC  month_FEB  month_JAN  month_JUL  month_JUN  month_MAR  month_MAY  month_NOV  month_OCT  month_SEP  year_2013  year_2014  year_2015  \\\n",
       "0       0      29.0         1.0        0.0      0.0   2.6     7.7   0.0       0.0  train          25.0                  1.40              0.20        0.200000                      0.052372            0.002743                    0.206743               0.32                        0.32               0.16                   3.08               0.20         0.220000                       0.070508             0.004971                     0.231023                0.40                         0.40                0.12                   5.88               0.20         0.210000                       0.080445             0.006471                     0.224881                 0.4                          0.4                0.04    0.00            1            0            0            0            0            0            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "1       1      30.0         0.0        0.0      1.0   4.4     7.1   0.0      60.0  train          25.0                  1.20              0.16        0.171429                      0.087412            0.007641                    0.192428               0.32                        0.32               0.00                   2.80               0.20         0.200000                       0.088156             0.007771                     0.218567                0.40                         0.40                0.00                   5.64               0.20         0.201429                       0.089111             0.007941                     0.220260                 0.4                          0.4                0.00    1.00            0            0            1            0            0            0            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "2       2      31.0         0.0        0.0      1.0   4.8     3.0   0.0     258.0  train          25.0                  2.04              0.20        0.291429                      0.302156            0.091298                    0.419796               1.00                        1.00               0.00                   3.40               0.20         0.242857                       0.220889             0.048792                     0.328286                1.00                         1.00                0.00                   6.32               0.20         0.225714                       0.172118             0.029624                     0.283851                 1.0                          1.0                0.00    0.12            0            0            0            1            0            0            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "3       3      32.0         0.0        0.0      0.0   5.1     7.6   0.1      19.0  train          25.0                  1.84              0.16        0.262857                      0.307511            0.094563                    0.404546               1.00                        1.00               0.00                   3.28               0.20         0.234286                       0.223150             0.049796                     0.323552                1.00                         1.00                0.00                   6.20               0.20         0.221429                       0.173199             0.029998                     0.281120                 1.0                          1.0                0.00    0.00            0            1            0            0            0            0            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "4       4      33.0         0.0        0.0      0.0   3.5     4.4   0.3     314.0  train          25.0                  1.64              0.16        0.234286                      0.321019            0.103053                    0.397420               1.00                        1.00               0.00                   3.08               0.18         0.220000                       0.231146             0.053429                     0.319106                1.00                         1.00                0.00                   6.04               0.20         0.215714                       0.177712             0.031582                     0.279489                 1.0                          1.0                0.00    0.08            0            0            0            0            0            1            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "..    ...       ...         ...        ...      ...   ...     ...   ...       ...    ...           ...                   ...               ...             ...                           ...                 ...                         ...                ...                         ...                ...                    ...                ...              ...                            ...                  ...                          ...                 ...                          ...                 ...                    ...                ...              ...                            ...                  ...                          ...                 ...                          ...                 ...     ...          ...          ...          ...          ...          ...          ...          ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...   \n",
       "25     25      54.0         0.0        0.0      0.0   3.0     5.5   0.0     125.0  train          25.0                  1.36              0.16        0.194286                      0.044994            0.002024                    0.199428               0.28                        0.28               0.16                   2.36               0.16         0.168571                       0.064460             0.004155                     0.180476                0.28                         0.28                0.04                   5.52               0.16         0.197143                       0.174333             0.030392                     0.263168                 1.0                          1.0                0.00    0.16            0            0            0            0            0            1            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "26     26      55.0         0.0        0.0      0.0   1.5     1.9   0.0     288.0  train          25.0                  1.36              0.16        0.194286                      0.044994            0.002024                    0.199428               0.28                        0.28               0.16                   2.44               0.16         0.174286                       0.059727             0.003567                     0.184236                0.28                         0.28                0.04                   5.48               0.16         0.195714                       0.174467             0.030439                     0.262189                 1.0                          1.0                0.00    0.04            0            0            0            0            0            0            1          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "27     27      56.0         0.0        0.0      0.0   1.1     7.8   0.4       0.0  train          25.0                  1.20              0.16        0.171429                      0.069985            0.004898                    0.185164               0.28                        0.28               0.04                   2.32               0.16         0.165714                       0.069046             0.004767                     0.179523                0.28                         0.28                0.04                   5.36               0.16         0.191429                       0.176751             0.031241                     0.260549                 1.0                          1.0                0.00    0.16            0            0            0            0            1            0            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "28     28      57.0         0.0        0.0      0.0   3.4     7.9   0.0       0.0  train          25.0                  1.08              0.16        0.154286                      0.054210            0.002939                    0.163532               0.24                        0.24               0.04                   2.36               0.16         0.168571                       0.067914             0.004612                     0.181738                0.28                         0.28                0.04                   5.36               0.16         0.191429                       0.176751             0.031241                     0.260549                 1.0                          1.0                0.00    0.20            1            0            0            0            0            0            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "29     29      58.0         0.0        0.0      1.0   2.4     7.5   0.0     116.0  train          25.0                  1.12              0.16        0.160000                      0.056569            0.003200                    0.169706               0.24                        0.24               0.04                   2.28               0.16         0.162857                       0.061345             0.003763                     0.174028                0.28                         0.28                0.04                   5.56               0.16         0.198571                       0.172869             0.029884                     0.263276                 1.0                          1.0                0.00    0.52            0            0            1            0            0            0            0          0          0          0          0          0          0          0          0          0          1          0          0          1          0          0   \n",
       "\n",
       "    item_calamari  item_chicken  item_fish  item_koefte  item_lamb  item_shrimp  item_steak id_for_CV  dummyID  \n",
       "0               1             0          0            0          0            0           0  calamari  dummyID  \n",
       "1               1             0          0            0          0            0           0  calamari  dummyID  \n",
       "2               1             0          0            0          0            0           0  calamari  dummyID  \n",
       "3               1             0          0            0          0            0           0  calamari  dummyID  \n",
       "4               1             0          0            0          0            0           0  calamari  dummyID  \n",
       "..            ...           ...        ...          ...        ...          ...         ...       ...      ...  \n",
       "25              1             0          0            0          0            0           0  calamari  dummyID  \n",
       "26              1             0          0            0          0            0           0  calamari  dummyID  \n",
       "27              1             0          0            0          0            0           0  calamari  dummyID  \n",
       "28              1             0          0            0          0            0           0  calamari  dummyID  \n",
       "29              1             0          0            0          0            0           0  calamari  dummyID  \n",
       "\n",
       "[30 rows x 70 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dummyID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_for_CV</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>calamari</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calamari</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calamari</th>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dummyID\n",
       "id_for_CV         \n",
       "calamari      0.00\n",
       "calamari      1.00\n",
       "calamari      0.12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Zeilen: 4627\n",
      "Anzahl der targets: 1\n"
     ]
    }
   ],
   "source": [
    "dataset_name = config.dataset_name\n",
    "\n",
    "# Hole die Datei-ID für den gewählten Datensatz\n",
    "file_id = {\n",
    "    'bakery': '1r_bDn9Z3Q_XgeTTkJL7352nUG3jkUM0z',\n",
    "    'yaz': '1xrY3Uv5F9F9ofgSM7dVoSK4bE0gPMg36',\n",
    "    'm5': '1tCBaxOgE5HHllvLVeRC18zvALBz6B-6w',\n",
    "    'sid': '1J9bPCfeLDH-mbSnvTHRoCva7pl6cXD3_',\n",
    "    'air': '1SKPpNxulcusNTjRwCC0p3C_XW7aNBNJZ',\n",
    "    \"copula\": '1H5wdJgmxdhbzeS17w0NkRlHRCESEAd-e',\n",
    "    'wage': '1bn7E7NOoRzE4NwXXs1MYhRSKZHC13qYU',\n",
    "}[config.dataset_name]\n",
    "\n",
    "\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "\n",
    "# Datei herunterladen\n",
    "output = f\"{dataset_name}.csv\"\n",
    "gdown.download(url, output, quiet=False)\n",
    "data = pd.read_csv(output)\n",
    "\n",
    "# Erstelle die Dataset-Einstellungen basierend auf den geladenen Daten\n",
    "settings = get_dataset_settings(data)[dataset_name]\n",
    "\n",
    "y, train_data, test_data, X_train_features, X_test_features, y_train, y_test = preprocess_data(\n",
    "    data, settings['backscaling_columns'], settings['bool_columns'], settings['drop_columns'])\n",
    "\n",
    "\n",
    "display(X_train_features.head(30))\n",
    "display(y_train.head(3))\n",
    "print(f\"Anzahl der Zeilen: {len(y_train)}\")\n",
    "print(\"Anzahl der targets:\", len(y_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cu, co combination: cu=9, co=1\n",
      "Test length for column: 39 (6% of 661 Datapoints per Group\n",
      "Running model MLP for column dummyID, cu=9, co=1\n",
      "Evaluating model: MLP, cu: 9, co: 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'calculate_n_iter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m tau \u001b[38;5;241m=\u001b[39m cu \u001b[38;5;241m/\u001b[39m (cu \u001b[38;5;241m+\u001b[39m co)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Parallelize column processing within each combination with n_jobs=4 to limit threads\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m column_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_column\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mco\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Combine results from all columns and print after each column\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m column_results:\n",
      "File \u001b[0;32m~/WorkingFolder/new_enviroment/lib/python3.8/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/WorkingFolder/new_enviroment/lib/python3.8/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/WorkingFolder/scripts/full_dataset_training.py:236\u001b[0m, in \u001b[0;36mprocess_column\u001b[0;34m(column, cu, co, tau, y_train, X_train_features, X_test_features, y_test, random_state)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model_name, model, param_grid \u001b[38;5;129;01min\u001b[39;00m other_models:\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for column \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, cu=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, co=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mco\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 236\u001b[0m         \u001b[43mevaluate_and_append_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43my_train_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaa_pinball_losses_per_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mco\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled_withID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m result_table \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m    241\u001b[0m     table_rows,\n\u001b[1;32m    242\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVariable\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mco\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPinball Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Params\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta C\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msl\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    243\u001b[0m )\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28mprint\u001b[39m(result_table\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m7\u001b[39m))\n",
      "File \u001b[0;32m~/WorkingFolder/scripts/full_dataset_training.py:107\u001b[0m, in \u001b[0;36mevaluate_and_append_models\u001b[0;34m(models, X_train_scaled, X_test_scaled, y_train_col, y_test_col, saa_pinball_losses_per_id, tau, cu, co, column, table_rows, timeseries, X_test_scaled_withID)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model, param_grid \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, cu: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, co: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mco\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 107\u001b[0m     pinball_loss_value, best_params, predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mco\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# Create DataFrame for model predictions\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     predictions_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_for_CV\u001b[39m\u001b[38;5;124m'\u001b[39m: X_test_scaled_withID[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid_for_CV\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m'\u001b[39m: y_test_col\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions\n\u001b[1;32m    117\u001b[0m     })\n",
      "File \u001b[0;32m~/WorkingFolder/scripts/full_dataset_training.py:171\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(model_name, model, param_grid, X_train_scaled, X_test_scaled, y_train, y_test, tau, cu, co, timeseries, column)\u001b[0m\n\u001b[1;32m    168\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m CV\u001b[38;5;241m.\u001b[39mbestParams_perProb[tau]\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m# Perform Bayesian search for other models\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m     model, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mbayesian_search_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mco\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDRF\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    175\u001b[0m         predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled, quantile\u001b[38;5;241m=\u001b[39mtau)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[0;32m~/WorkingFolder/scripts/full_dataset_training.py:361\u001b[0m, in \u001b[0;36mbayesian_search_model\u001b[0;34m(model_name, model, param_grid, X_train, y_train, tau, cu, co, n_points, n_initial_points, n_jobs, column)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbayesian_search_model\u001b[39m(model_name, model, param_grid, X_train, y_train, tau, cu, co, n_points, n_initial_points, n_jobs, column):\n\u001b[1;32m    359\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m pinball_loss_scorer(tau)\n\u001b[0;32m--> 361\u001b[0m     max_combinations \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_n_iter\u001b[49m(param_grid)\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    364\u001b[0m         n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m80\u001b[39m  \u001b[38;5;66;03m# Higher number of iterations for LGBM since we have more params here\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calculate_n_iter' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Execution starts here\n",
    "combinations = [(9, 1), (7.5, 2.5), (5, 5), (2.5, 7.5), (1, 9)]\n",
    "table_rows = []\n",
    "random_state = 1\n",
    "global_cv_results = []\n",
    "\n",
    "# Initialize cvFolds\n",
    "cvFolds = None  # Initialization\n",
    "\n",
    "for cu, co in combinations:\n",
    "    print(f\"Processing cu, co combination: cu={cu}, co={co}\")\n",
    "    tau = cu / (cu + co)\n",
    "\n",
    "    # Parallelize column processing within each combination with n_jobs=4 to limit threads\n",
    "    column_results = Parallel(n_jobs=1)(\n",
    "        delayed(process_column)(column, cu, co, tau, y_train, X_train_features, X_test_features, y_test, random_state)\n",
    "        for column in y_train.columns\n",
    "    )\n",
    "\n",
    "    # Combine results from all columns and print after each column\n",
    "    for result in column_results:\n",
    "        table_rows.extend(result)\n",
    "        print(table_rows)\n",
    "        # Convert the latest result to a DataFrame and print it\n",
    "        result_table = pd.DataFrame(table_rows, columns=['Variable', 'cu', 'co', 'Model', 'Pinball Loss', 'Best Params', 'delta C', 'sl'])\n",
    "        print(result_table)  # Print the updated results after each column is processed\n",
    "\n",
    "# Final result table after processing all combinations\n",
    "result_table = pd.DataFrame(table_rows, columns=['Variable', 'cu', 'co', 'Model', 'Pinball Loss', 'Best Params', 'delta C', 'sl'])\n",
    "\n",
    "# Construct the filename using the format \"results_basicModels_{dataset_name}.csv\"\n",
    "filename = f\"FULLDATASET_results_basic_Models_{dataset_name}.csv\"\n",
    "result_table.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Results saved as {filename}\")\n",
    "\n",
    "# Aggregate and save cross-validation results at the end of the entire workflow\n",
    "if global_cv_results:\n",
    "    # Concatenate all cross-validation results into a single DataFrame\n",
    "    aggregated_cv_results_df = pd.concat(global_cv_results, ignore_index=True)\n",
    "\n",
    "    # Print a summary of the aggregated cross-validation data to verify it looks correct\n",
    "    print(\"Aggregated cross-validation results sample:\")\n",
    "    print(aggregated_cv_results_df.head(5))  # Print the first 5 rows as a sample\n",
    "\n",
    "    # Save the aggregated results to a CSV file\n",
    "    aggregated_cv_filename = f\"FULLDATASET_cv_scores_basic_models_{dataset_name}.csv\"\n",
    "    aggregated_cv_results_df.to_csv(aggregated_cv_filename, index=False)\n",
    "    print(f\"Aggregated cross-validation results saved as {aggregated_cv_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
