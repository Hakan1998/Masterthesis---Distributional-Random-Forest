{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_colors =  {\n",
    "    \"RFW\": \"#1f77b4\",          # Blue\n",
    "    \"KNNW\": \"#ff7f0e\",         # Orange\n",
    "    \"DTW\": \"#2ca02c\",          # Green\n",
    "    \"GKW\": \"#17becf\",          # Cyan (new color for GKW)\n",
    "    \"LS_KDEx_LGBM\": \"#9467bd\", # Purple\n",
    "    \"LS_KDEx_MLP\": \"#8c564b\",  # Brown\n",
    "    \"DRF\": \"#e74c3c\",          # Highlighted Red (focused model)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"/workspaces/Masterthesis-DRF/Results/aggregated_results/results_combined_allDatasets.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Exclude specific models\n",
    "excluded_models = ['SAA', 'MLP', 'LGBM']\n",
    "filtered_df = df[~df['Model'].isin(excluded_models)]\n",
    "\n",
    "# Dataset names for both training types\n",
    "dataset_names = {\n",
    "    \"ID-Based Training\": ['air', 'bakery', 'm5', 'wage', 'yaz'],\n",
    "    \"Full Data Training\": ['subset_air', 'subset_bakery', 'subset_m5', 'wage', 'yaz']\n",
    "}\n",
    "\n",
    "# SL values to consider\n",
    "sl_values = [0.9, 0.75, 0.5, 0.25, 0.1]\n",
    "\n",
    "# Extended color palette (Beispiel: Definiere hier dein Farben-Wörterbuch)\n",
    "model_colors = {\n",
    "    \"RFW\": \"#1f77b4\",\n",
    "    \"KNNW\": \"#ff7f0e\",\n",
    "    \"DTW\": \"#2ca02c\",\n",
    "    \"GKW\": \"#d62728\",\n",
    "    \"LS_KDEx_LGBM\": \"#9467bd\",\n",
    "    \"LS_KDEx_MLP\": \"#8c564b\",\n",
    "    \"DRF\": \"#e377c2\"\n",
    "}\n",
    "\n",
    "# Unified model order\n",
    "model_order = [\"RFW\", \"KNNW\", \"DTW\", \"GKW\", \"LS_KDEx_LGBM\", \"LS_KDEx_MLP\", \"DRF\"]\n",
    "\n",
    "# Iterate over both training types\n",
    "for training_type, datasets in dataset_names.items():\n",
    "    num_rows = len(sl_values)\n",
    "    num_cols = len(datasets)\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 25), sharex=True, sharey=True)  # Angepasste Größe\n",
    "\n",
    "    for row, sl in enumerate(sl_values):\n",
    "        for col, dataset in enumerate(datasets):\n",
    "            ax = axes[row, col]\n",
    "            # Filter data for the specific dataset, training type, and SL value\n",
    "            filtered_data = filtered_df[\n",
    "                (filtered_df['dataset'] == dataset) &\n",
    "                (filtered_df['training_description'] == training_type) &\n",
    "                (filtered_df['sl'] == sl)\n",
    "            ]\n",
    "            \n",
    "            # Plot KDE für jedes Modell\n",
    "            for model in model_order:\n",
    "                model_data = filtered_data[filtered_data['Model'] == model]['delta C']\n",
    "                if not model_data.empty:\n",
    "                    sns.kdeplot(\n",
    "                        model_data,\n",
    "                        ax=ax,\n",
    "                        label=model,\n",
    "                        color=model_colors.get(model, \"gray\"),\n",
    "                        fill=False,  # Keine Füllung unter der Kurve\n",
    "                        linewidth=1\n",
    "                    )\n",
    "            \n",
    "            # Set y-axis range from 0 to 1\n",
    "            ax.set_ylim(0, 2)\n",
    "            \n",
    "            # Optional: Set x-axis limits based on data\n",
    "            # Hier wird der Minimal- und Maximalwert der 'delta C' für alle Modelle im aktuellen Filter gesetzt\n",
    "            if not filtered_data['delta C'].empty:\n",
    "                x_min = -0.5\n",
    "                x_max = 1\n",
    "                ax.set_xlim(x_min, x_max)\n",
    "            \n",
    "            # Add dashed line at y=0\n",
    "            ax.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "\n",
    "            # Set dataset title once at the top row\n",
    "            if row == 0:\n",
    "                ax.set_title(f'{dataset}', fontsize=14, pad=15)  # Dataset title\n",
    "            \n",
    "            # Add SL description on the y-axis for the leftmost plots\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(f'SL: {sl}', fontsize=12)\n",
    "            else:\n",
    "                ax.set_ylabel('')\n",
    "            \n",
    "            # Remove \"Model\" label from the last row\n",
    "            if row == num_rows - 1:\n",
    "                ax.set_xlabel('Delta C', fontsize=12)  # X-Achsenbeschriftung\n",
    "            \n",
    "            # Optional: Entferne Tick-Labels auf der X-Achse, wenn gewünscht\n",
    "            # ax.set_xticks([])\n",
    "    \n",
    "    # Add a global Y-axis label for all plots\n",
    "    fig.supylabel('Dichte', fontsize=16)  # 'Delta C' war zuvor auf der Y-Achse\n",
    "\n",
    "    # Add a legend below the plots\n",
    "    handles = [plt.Line2D([0], [0], color=color, lw=2) for color in model_colors.values()]\n",
    "    labels = model_colors.keys()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=len(model_colors), fontsize=12, frameon=False)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])  # Adjust layout to make space for the legend\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.3)  # Adjust spacing between plots\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"/workspaces/Masterthesis-DRF/Results/aggregated_results/results_combined_allDatasets.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Exclude specific models\n",
    "excluded_models = ['SAA', 'MLP', 'LGBM']\n",
    "filtered_df = df[~df['Model'].isin(excluded_models)]\n",
    "\n",
    "# Dataset names for both training types\n",
    "dataset_names = {\n",
    "    \"ID-Based Training\": ['air', 'bakery', 'm5', 'wage', 'yaz'],\n",
    "    \"Full Data Training\": ['subset_air', 'subset_bakery', 'subset_m5', 'wage', 'yaz']\n",
    "}\n",
    "\n",
    "# SL values to consider\n",
    "sl_values = [0.9, 0.75, 0.5, 0.25, 0.1]\n",
    "\n",
    "# Extended color palette\n",
    "model_colors = model_colors\n",
    "\n",
    "# Unified model order\n",
    "model_order = [\"RFW\", \"KNNW\", \"DTW\", \"GKW\", \"LS_KDEx_LGBM\", \"LS_KDEx_MLP\", \"DRF\"]\n",
    "\n",
    "# Fixed Y-axis ranges\n",
    "global_y_min = -0.3\n",
    "global_y_max = 0.9\n",
    "wage_y_min = -0.1  # Zoomed-in lower bound for wage dataset\n",
    "wage_y_max = 0.3   # Zoomed-in upper bound for wage dataset\n",
    "\n",
    "# Iterate over both training types\n",
    "for training_type, datasets in dataset_names.items():\n",
    "    num_rows = len(sl_values)\n",
    "    num_cols = len(datasets)\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 18), sharex=True, sharey=True)  # Increased height\n",
    "\n",
    "    for row, sl in enumerate(sl_values):\n",
    "        for col, dataset in enumerate(datasets):\n",
    "            ax = axes[row, col]\n",
    "            # Filter data for the specific dataset, training type, and SL value\n",
    "            filtered_data = filtered_df[\n",
    "                (filtered_df['dataset'] == dataset) &\n",
    "                (filtered_df['training_description'] == training_type) &\n",
    "                (filtered_df['sl'] == sl)\n",
    "            ]\n",
    "            \n",
    "            sns.boxplot(\n",
    "                ax=ax, x='Model', y='delta C', data=filtered_data,\n",
    "                showfliers=False, width=0.5, order=model_order, hue='Model',\n",
    "                palette=model_colors, dodge=False, legend=False\n",
    "            )\n",
    "\n",
    "            # Adjust marker size for points\n",
    "            for line in ax.lines:\n",
    "                line.set_markersize(2)\n",
    "\n",
    "            # Set y-axis range based on dataset\n",
    "            if dataset == \"wage\":\n",
    "                ax.set_ylim(wage_y_min, wage_y_max)  # Zoomed-in range for wage\n",
    "            else:\n",
    "                ax.set_ylim(global_y_min, global_y_max)  # Default range for other datasets\n",
    "\n",
    "            # Add dashed line at y=0\n",
    "            ax.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "\n",
    "            # Set dataset title once at the top row\n",
    "            if row == 0:\n",
    "                ax.set_title(f'{dataset}', fontsize=16)  # Dataset title\n",
    "            \n",
    "            # Add SL description on the y-axis for the leftmost plots\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(f'SL: {sl}', fontsize=16)\n",
    "            else:\n",
    "                ax.set_ylabel('')\n",
    "\n",
    "            # Remove \"Model\" label from the last row\n",
    "            if row == num_rows - 1:\n",
    "                ax.set_xlabel('')  # Remove \"Model\" text from x-axis\n",
    "            \n",
    "            # Keep X-axis ticks but remove tick labels\n",
    "            ax.set_xticks(range(len(model_order)))  # Ensure ticks are present\n",
    "            ax.set_xticklabels([])  # Remove tick labels\n",
    "\n",
    "    # Add a global Y-axis label for all plots\n",
    "    fig.supylabel('Delta C', fontsize=16)\n",
    "\n",
    "    # Add a legend below the plots\n",
    "    handles = [plt.Line2D([0], [0], color=color, lw=4) for color in model_colors.values()]\n",
    "    labels = model_colors.keys()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=len(model_colors), fontsize=12, frameon=False)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])  # Reduced space between legend and plots\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.1)  # Increased spacing between plots\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pfad zur Datei\n",
    "file_path = \"/workspaces/Masterthesis-DRF/Results/aggregated_results/results_combined_allDatasets.csv\"\n",
    "\n",
    "# CSV-Datei laden\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Modelle ausschließen (Filterung vor der Schleife)\n",
    "excluded_models = ['SAA', 'MLP', 'LGBM']\n",
    "filtered_df = df[~df['Model'].isin(excluded_models)]\n",
    "\n",
    "# Datensätze für beide Training-Typen\n",
    "dataset_names = {\n",
    "    \"ID-Based Training\": ['air', 'bakery', 'm5', 'wage', 'yaz'],\n",
    "    \"Full Data Training\": ['subset_air', 'subset_bakery', 'subset_m5', 'wage', 'yaz']\n",
    "\n",
    "}\n",
    "\n",
    "# Erweiterte Farbpalette\n",
    "model_colors = model_colors\n",
    "# Einheitliche Modellreihenfolge\n",
    "model_order = [\"RFW\", \"KNNW\", \"DTW\", \"GKW\", \"LS_KDEx_LGBM\", \"LS_KDEx_MLP\", \"DRF\"]\n",
    "\n",
    "# Erstelle die Subplots\n",
    "fig, axes = plt.subplots(2, len(dataset_names[\"ID-Based Training\"]), figsize=(8.27, 10), sharey=True)\n",
    "\n",
    "# Setze Titel und X-Achsenbeschriftungen korrekt\n",
    "for row, (training_type, datasets) in enumerate(dataset_names.items()):\n",
    "    for col, dataset in enumerate(datasets):\n",
    "        ax = axes[row, col]\n",
    "        # Filter für spezifisches Dataset und Training-Typ\n",
    "        filtered_data = filtered_df[\n",
    "            (filtered_df['dataset'] == dataset) & \n",
    "            (filtered_df['training_description'] == training_type)\n",
    "        ]\n",
    "\n",
    "        # Bestes Modell für das aktuelle Dataset basierend auf dem Durchschnitt von delta C\n",
    "        best_model = filtered_data.groupby('Model')['delta C'].mean().idxmax()\n",
    "\n",
    "        # Linienplot für alle Modelle\n",
    "        for model in model_order:\n",
    "            model_data = filtered_data[filtered_data['Model'] == model]\n",
    "            sns.lineplot(\n",
    "                ax=ax, data=model_data, x='sl', y='delta C', label=model,\n",
    "                color=model_colors[model], marker='o', linewidth=3 if model == best_model else 1,\n",
    "                errorbar=None\n",
    "            )\n",
    "\n",
    "        # Füge gestrichelte Linie bei y=0 hinzu\n",
    "        ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "        # Setze Titel für die obere Zeile\n",
    "        if row == 0:\n",
    "            ax.set_title(f'{dataset}', fontsize=10)\n",
    "\n",
    "        # Setze Titel für die untere Zeile, inkl. vollständigem Datensatznamen\n",
    "        if row == 1:\n",
    "            mapped_dataset = dataset\n",
    "            ax.set_title(f'{mapped_dataset}', fontsize=10)\n",
    "\n",
    "        # Entferne X-Achsenbeschriftung und Ticks für die obere Zeile\n",
    "        if row == 0:\n",
    "            ax.set_xticks([])  # Entfernt die X-Achsen-Ticks\n",
    "            ax.set_xlabel('')  # Entfernt \"sl\"\n",
    "\n",
    "        # Setze die X-Achsenpunkte auf spezifische Werte für die untere Zeile\n",
    "        if row == 1:\n",
    "            ax.set_xticks([0.1, 0.25, 0.5, 0.75, 0.9])\n",
    "            ax.set_xticklabels(['0.1', '0.25', '0.5', '0.75', '0.9'], fontsize=8)  # Nur Zahlenwerte\n",
    "            ax.set_xlabel('')  # Entfernt \"sl\"\n",
    "        # Entferne die Legende von den Subplots\n",
    "        ax.get_legend().remove()\n",
    "\n",
    "# Globale Legende unterhalb der Grafik\n",
    "handles = [plt.Line2D([0], [0], color=color, lw=2, label=model) for model, color in model_colors.items()]\n",
    "fig.legend(handles, model_colors.keys(), loc='lower center', ncol=len(model_colors), fontsize=10, frameon=True)\n",
    "\n",
    "# Passen Sie den Abstand zwischen den Subplots an\n",
    "plt.subplots_adjust(hspace=0.2)  # Abstand zwischen den beiden Plot-Reihen\n",
    "\n",
    "# Untertitel für beide Plots\n",
    "plt.figtext(0.5, 0.94, 'ID-Based Training', ha='center', fontsize=10, weight='bold')  # Erster Untertitel\n",
    "plt.figtext(0.5, 0.5, 'Full Data Training', ha='center', fontsize=10, weight='bold')  # Zweiter Untertitel, direkt über dem unteren Plot\n",
    "\n",
    "# Gemeinsame X-Achsenbeschriftung\n",
    "fig.supxlabel('Service Level', fontsize=10, y=0.05)  # Position leicht oberhalb der Legende\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Ihre bereitgestellte model_colors-Palette\n",
    "model_colors =  {\n",
    "    \"RFW\": \"#1f77b4\",          # Blue\n",
    "    \"KNNW\": \"#ff7f0e\",         # Orange\n",
    "    \"DTW\": \"#2ca02c\",          # Green\n",
    "    \"GKW\": \"#17becf\",          # Cyan (new color for GKW)\n",
    "    \"LS_KDEx_LGBM\": \"#9467bd\", # Purple\n",
    "    \"LS_KDEx_MLP\": \"#8c564b\",  # Brown\n",
    "    \"DRF\": \"#e74c3c\",          # Highlighted Red (focused model)\n",
    "}\n",
    "\n",
    "# Pfad zur CSV-Datei\n",
    "file_path = \"/workspaces/Masterthesis-DRF/Results/aggregated_results/results_combined_allDatasets.csv\"\n",
    "\n",
    "# Laden der CSV-Datei mit Fehlerbehandlung\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except Exception as e:\n",
    "    raise SystemExit(f\"Fehler beim Laden der CSV-Datei: {e}\")\n",
    "\n",
    "# Überprüfen der Spalten in der CSV-Datei\n",
    "expected_columns = {'Model', 'training_description', 'dataset', 'sl', 'Variable', 'Pinball Loss'}\n",
    "if not expected_columns.issubset(df.columns):\n",
    "    raise SystemExit(f\"Fehlende erwartete Spalten. Erwartet: {expected_columns}, Gefunden: {df.columns}\")\n",
    "\n",
    "# Ausschließen bestimmter Modelle\n",
    "excluded_models = ['SAA', 'MLP', 'LGBM']\n",
    "filtered_df = df[~df['Model'].isin(excluded_models)]\n",
    "\n",
    "# Überprüfen der verbleibenden Modelle\n",
    "remaining_models = filtered_df['Model'].unique()\n",
    "\n",
    "# Sicherstellen, dass alle verbleibenden Modelle in model_colors definiert sind\n",
    "for model in remaining_models:\n",
    "    if model not in model_colors:\n",
    "        model_colors[model] = 'gray'  # Standardfarbe für nicht definierte Modelle\n",
    "\n",
    "# Einzigartige Trainingsbeschreibungen\n",
    "training_descriptions = filtered_df['training_description'].unique()\n",
    "\n",
    "# Bestimmen der maximalen Anzahl an Datasets pro Trainingsbeschreibung\n",
    "datasets_per_training = [filtered_df[filtered_df['training_description'] == td]['dataset'].nunique() for td in training_descriptions]\n",
    "max_datasets = max(datasets_per_training) if datasets_per_training else 0\n",
    "\n",
    "# Bestimmen der Anzahl der Trainingsbeschreibungen\n",
    "num_trainings = len(training_descriptions)\n",
    "\n",
    "# Erstellen einer einzigen Figur mit mehreren Subplots\n",
    "# Layout: nrows = Anzahl der Trainingsbeschreibungen, ncols = maximale Anzahl der Datasets\n",
    "# Optimierung für DIN A4: 11.69 x 8.27 inches\n",
    "fig_width = 11.69\n",
    "fig_height = 8.27\n",
    "fig, axes = plt.subplots(nrows=num_trainings, ncols=max_datasets, figsize=(fig_width, fig_height), sharey=True)\n",
    "\n",
    "# Sicherstellen, dass axes immer ein 2D-Array ist\n",
    "if num_trainings == 1 and max_datasets == 1:\n",
    "    axes = np.array([[axes]])\n",
    "elif num_trainings == 1:\n",
    "    axes = axes.reshape(1, max_datasets)\n",
    "elif max_datasets == 1:\n",
    "    axes = axes.reshape(num_trainings, 1)\n",
    "\n",
    "# Loop über jede Trainingsbeschreibung\n",
    "for row_idx, td in enumerate(training_descriptions):\n",
    "    td_df = filtered_df[filtered_df['training_description'] == td]\n",
    "    datasets = td_df['dataset'].unique()\n",
    "    num_datasets = len(datasets)\n",
    "\n",
    "    for col_idx in range(max_datasets):\n",
    "        ax = axes[row_idx, col_idx]\n",
    "        ax.set_title(\"\")\n",
    "\n",
    "        if col_idx < num_datasets:\n",
    "            dataset = datasets[col_idx]\n",
    "            dataset_df = td_df[td_df['dataset'] == dataset]\n",
    "            service_levels = sorted(dataset_df['sl'].unique())\n",
    "            variables = dataset_df['Variable'].unique()\n",
    "\n",
    "            if len(service_levels) == 0 or len(variables) == 0:\n",
    "                ax.set_visible(False)\n",
    "                continue\n",
    "\n",
    "            # Initialisieren eines Dictionaries zur Speicherung der besten Modellanzahlen pro Service Level\n",
    "            best_model_counts_per_sl = {}\n",
    "            for sl in service_levels:\n",
    "                sl_df = dataset_df[dataset_df['sl'] == sl]\n",
    "                # Initialisieren eines Dictionaries zur Zählung der besten Modelle\n",
    "                best_model_counts = {model: 0 for model in model_colors.keys()}\n",
    "                # Loop über jede Variable\n",
    "                for var in variables:\n",
    "                    var_df = sl_df[sl_df['Variable'] == var]\n",
    "                    # Finden des Modells mit dem niedrigsten Pinball Loss\n",
    "                    if not var_df.empty:\n",
    "                        min_loss = var_df['Pinball Loss'].min()\n",
    "                        best_models = var_df[var_df['Pinball Loss'] == min_loss]['Model'].unique()\n",
    "                        # Bei Gleichstand den Count aufteilen\n",
    "                        count_increment = 1.0 / len(best_models)\n",
    "                        for bm in best_models:\n",
    "                            if bm in best_model_counts:\n",
    "                                best_model_counts[bm] += count_increment\n",
    "                # Umwandeln der Counts in Prozentsätze\n",
    "                total_vars = len(variables)\n",
    "                for model in best_model_counts:\n",
    "                    best_model_counts[model] = (best_model_counts[model] / total_vars) * 100\n",
    "                best_model_counts_per_sl[sl] = best_model_counts\n",
    "\n",
    "            # Berechnung der Gesamtprozentsätze pro Modell für dieses Dataset\n",
    "            total_percentages = {model: 0 for model in model_colors.keys()}\n",
    "            for sl in service_levels:\n",
    "                for model, perc in best_model_counts_per_sl[sl].items():\n",
    "                    total_percentages[model] += perc\n",
    "\n",
    "            # Sortieren der Modelle basierend auf den Gesamtprozentsätzen in absteigender Reihenfolge\n",
    "            sorted_models = sorted(total_percentages.keys(), key=lambda m: total_percentages[m], reverse=True)\n",
    "\n",
    "            # Plotten des gestapelten Balkendiagramms für dieses Dataset\n",
    "            x = np.arange(len(service_levels))  # Positionen auf der x-Achse\n",
    "            bottoms = np.zeros(len(service_levels))\n",
    "\n",
    "            # Plotten der Balken in der sortierten Reihenfolge\n",
    "            for model in sorted_models:\n",
    "                percentages = [best_model_counts_per_sl[sl][model] for sl in service_levels]\n",
    "                ax.bar(\n",
    "                    x,\n",
    "                    percentages,\n",
    "                    bottom=bottoms,\n",
    "                    color=model_colors.get(model, 'gray'),  # Farben immer aus model_colors\n",
    "                    label=model if (row_idx == 0 and col_idx == 0) else \"\"  # Nur einmal Label für Legende\n",
    "                )\n",
    "                bottoms += percentages\n",
    "\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels([str(sl) for sl in service_levels])  # Nur den Wert anzeigen\n",
    "            if col_idx == 0:\n",
    "                ax.set_ylabel('Percent', fontsize=12)\n",
    "            ax.set_title(f\"{dataset}\", fontsize=10)\n",
    "        else:\n",
    "            ax.set_visible(False)\n",
    "\n",
    "# Hinzufügen einer gemeinsamen X-Achsen-Beschriftung\n",
    "plt.subplots_adjust(bottom=0.15, top=0.9, left=0.1, right=0.95, hspace=0.4, wspace=0.3)\n",
    "fig.text(0.5, 0.08, 'Service Level', ha='center', va='center', fontsize=12)\n",
    "\n",
    "# Hinzufügen einer gemeinsamen Legende\n",
    "handles = [Patch(facecolor=model_colors[model], label=model) for model in model_colors.keys()]\n",
    "fig.legend(\n",
    "    handles,\n",
    "    [model for model in model_colors.keys()],\n",
    "    title='Models',\n",
    "    bbox_to_anchor=(0.5, -0.1),  # Position unterhalb der X-Achsen-Beschriftung\n",
    "    loc='lower center',\n",
    "    ncol=len(model_colors),\n",
    "    fontsize=10\n",
    ")\n",
    "plt.figtext(0.5, 0.96, 'ID-Based Training', ha='center', fontsize=10, weight='bold')  # Oberer Untertitel\n",
    "plt.figtext(0.5, 0.52, 'Full Data Training', ha='center', fontsize=10, weight='bold')  # Unterer Untertitel\n",
    "\n",
    "# Abstand zwischen den Subplots erhöhen\n",
    "plt.subplots_adjust(hspace=0.5)  # Erhöht den vertikalen Abstand\n",
    "\n",
    "# Anzeigen des Plots\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"/workspaces/Masterthesis-DRF/Results/aggregated_results/results_combined_allDatasets.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Exclude specific models\n",
    "excluded_models = ['SAA', 'MLP', 'LGBM']\n",
    "filtered_df = df[~df['Model'].isin(excluded_models)]\n",
    "\n",
    "# Dataset names for both training types\n",
    "dataset_names = {\n",
    "    \"ID-Based Training\": ['air', 'bakery', 'm5', 'wage', 'yaz'],\n",
    "    \"Full Data Training\": ['subset_air', 'subset_bakery', 'subset_m5', 'wage', 'yaz']\n",
    "\n",
    "}\n",
    "\n",
    "# SL values to consider\n",
    "sl_values = [0.9, 0.75, 0.5, 0.25, 0.1]\n",
    "\n",
    "# Extended color palette\n",
    "model_colors = model_colors\n",
    "\n",
    "# Unified model order\n",
    "model_order = [\"RFW\", \"KNNW\", \"DTW\", \"GKW\", \"LS_KDEx_LGBM\", \"LS_KDEx_MLP\", \"DRF\"]\n",
    "\n",
    "# Fixed Y-axis ranges\n",
    "global_y_min = -0.3\n",
    "global_y_max = 0.9\n",
    "wage_y_min = -0.1  # Zoomed-in lower bound for wage dataset\n",
    "wage_y_max = 0.3   # Zoomed-in upper bound for wage dataset\n",
    "\n",
    "# Iterate over both training types\n",
    "for training_type, datasets in dataset_names.items():\n",
    "    num_rows = len(sl_values)\n",
    "    num_cols = len(datasets)\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(18, 12), sharex=True, sharey=True)  # Increased height\n",
    "\n",
    "    for row, sl in enumerate(sl_values):\n",
    "        for col, dataset in enumerate(datasets):\n",
    "            ax = axes[row, col]\n",
    "            # Filter data for the specific dataset, training type, and SL value\n",
    "            filtered_data = filtered_df[\n",
    "                (filtered_df['dataset'] == dataset) &\n",
    "                (filtered_df['training_description'] == training_type) &\n",
    "                (filtered_df['sl'] == sl)\n",
    "            ]\n",
    "            \n",
    "            sns.boxplot(\n",
    "                ax=ax, x='Model', y='delta C', data=filtered_data,\n",
    "                showfliers=False, width=0.5, order=model_order, hue='Model',\n",
    "                palette=model_colors, dodge=False, legend=False\n",
    "            )\n",
    "\n",
    "            # Adjust marker size for points\n",
    "            for line in ax.lines:\n",
    "                line.set_markersize(2)\n",
    "\n",
    "            # Set y-axis range based on dataset\n",
    "            if dataset == \"wage\":\n",
    "                ax.set_ylim(wage_y_min, wage_y_max)  # Zoomed-in range for wage\n",
    "            else:\n",
    "                ax.set_ylim(global_y_min, global_y_max)  # Default range for other datasets\n",
    "\n",
    "            # Add dashed line at y=0\n",
    "            ax.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "\n",
    "            # Set dataset title once at the top row\n",
    "            if row == 0:\n",
    "                ax.set_title(f'{dataset}', fontsize=16)  # Dataset title\n",
    "            \n",
    "            # Add SL description on the y-axis for the leftmost plots\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(f'SL: {sl}', fontsize=16)\n",
    "            else:\n",
    "                ax.set_ylabel('')\n",
    "\n",
    "            # Remove \"Model\" label from the last row\n",
    "            if row == num_rows - 1:\n",
    "                ax.set_xlabel('')  # Remove \"Model\" text from x-axis\n",
    "            \n",
    "            # Keep X-axis ticks but remove tick labels\n",
    "            ax.set_xticks(range(len(model_order)))  # Ensure ticks are present\n",
    "            ax.set_xticklabels([])  # Remove tick labels\n",
    "\n",
    "    # Add a global Y-axis label for all plots\n",
    "    fig.supylabel('Delta C', fontsize=16)\n",
    "\n",
    "    # Add a legend below the plots\n",
    "    handles = [plt.Line2D([0], [0], color=color, lw=4) for color in model_colors.values()]\n",
    "    labels = model_colors.keys()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=len(model_colors), fontsize=12, frameon=False)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])  # Reduced space between legend and plots\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.1)  # Increased spacing between plots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Liste auszuschließender Modelle\n",
    "excluded_models = ['MLP', 'LGBM']\n",
    "\n",
    "# Daten für Modell-Ergebnisse laden und filtern\n",
    "results_file_path = \"/workspaces/Masterthesis-DRF/Results/aggregated_results/results_combined_allDatasets.csv\"\n",
    "\n",
    "model_results = pd.read_csv(results_file_path)\n",
    "model_results = model_results[~model_results['Model'].isin(excluded_models)]\n",
    "\n",
    "# Spalte 'Model' in 'model_name' umbenennen\n",
    "model_results.rename(columns={'Model': 'model_name'}, inplace=True)\n",
    "model_results.rename(columns={'Variable': 'variable'}, inplace=True)\n",
    "\n",
    "display(model_results)\n",
    "# Daten für Modell-Ergebnisse laden und filtern\n",
    "results_file_path = \"/workspaces/Masterthesis-DRF/Results/aggregated_results/crossValidation_results_allDatasets.csv\"\n",
    "\n",
    "cv_results = pd.read_csv(results_file_path)\n",
    "cv_results = cv_results[~cv_results['model_name'].isin(excluded_models)]\n",
    "cv_results.rename(columns={'tau': 'sl'}, inplace=True)\n",
    "\n",
    "cv_results_raw = cv_results\n",
    "\n",
    "# Identify the split columns\n",
    "split_columns = [col for col in cv_results.columns if col.startswith('split') and '_test_score' in col]\n",
    "\n",
    "# Multiply all split columns by -1 for rows where model_type is 'levelset_models'\n",
    "cv_results_raw.loc[cv_results['model_name'] == 'DRF', 'model_type'] = 'basic_models'\n",
    "cv_results_raw.loc[cv_results['model_type'] == 'levelset_models', split_columns] *= -1\n",
    "\n",
    "\n",
    "display(cv_results_raw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kopieren der rohen CV-Ergebnisse\n",
    "cv_results = cv_results_raw.copy()\n",
    "\n",
    "# Berechnung des mean_test_score\n",
    "cv_results['mean_test_score'] = cv_results[\n",
    "    [col for col in cv_results.columns if col.startswith('split') and '_test_score' in col]\n",
    "].mean(axis=1)\n",
    "\n",
    "# Auswahl relevanter Spalten\n",
    "cv_results = cv_results[['mean_test_score', 'dataset', 'training_description',\n",
    "                         'variable', 'model_name', 'sl', 'hyperparameter']]\n",
    "\n",
    "# Definieren der Datensätze basierend auf den Trainingsbeschreibungen\n",
    "dataset_names = {\n",
    "    \"ID-Based Training\": ['air', 'bakery', 'm5', 'wage', 'yaz'],\n",
    "    \"Full Data Training\": ['subset_air', 'subset_bakery', 'subset_m5', 'wage', 'yaz']\n",
    "\n",
    "}\n",
    "\n",
    "# Initialisiere die Endtabelle\n",
    "final_best_models = pd.DataFrame()\n",
    "\n",
    "# Verarbeitung je Training Description\n",
    "for training_desc, datasets in dataset_names.items():\n",
    "    # Filtere die Daten für die aktuelle Trainingsbeschreibung\n",
    "    filtered_cv_results = cv_results[\n",
    "        (cv_results['training_description'] == training_desc) &\n",
    "        (cv_results['dataset'].isin(datasets))\n",
    "    ]\n",
    "    \n",
    "    # Auswahl der besten Modelle pro Parameter-Gitter\n",
    "    best_model_per_grid = filtered_cv_results.loc[\n",
    "        filtered_cv_results.groupby([\"dataset\", \"variable\", \"model_name\", \"sl\"])[\"mean_test_score\"].idxmax()\n",
    "    ]\n",
    "\n",
    "    # Rangordnung der besten Modelle\n",
    "    best_model_per_grid[\"rank\"] = best_model_per_grid.groupby(\n",
    "        [\"dataset\", \"variable\", \"sl\"]\n",
    "    )[\"mean_test_score\"].rank(\"min\", ascending=False)\n",
    "\n",
    "    # Auswahl der besten Modelle pro Kombination\n",
    "    best_cv_model_per_group = best_model_per_grid.loc[\n",
    "        best_model_per_grid.groupby([\"dataset\", \"variable\", \"sl\"])[\"mean_test_score\"].idxmax()\n",
    "    ]\n",
    "\n",
    "    # Hinzufügen zur Endtabelle\n",
    "    final_best_models = pd.concat([final_best_models, best_cv_model_per_group])\n",
    "\n",
    "# Zähle, wie oft jedes Modell das beste Modell war, gruppiert nach Dataset und Training Description\n",
    "best_model_counts = final_best_models.groupby([\"dataset\", \"training_description\"])[\"model_name\"].value_counts()\n",
    "\n",
    "# Endtabelle anzeigen\n",
    "display(final_best_models)\n",
    "\n",
    "best_cv_models = final_best_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split von best_cv_models nach \"training_description\"\n",
    "id_based_models = best_cv_models[best_cv_models['training_description'] == \"ID-Based Training\"]\n",
    "full_data_models = best_cv_models[best_cv_models['training_description'] == \"Full Data Training\"]\n",
    "\n",
    "# Merge für \"ID-Based Training\"\n",
    "id_based_result = id_based_models.merge(\n",
    "    model_results[model_results['training_description'] == \"ID-Based Training\"],\n",
    "    on=[\"dataset\", \"training_description\", \"variable\", \"model_name\", \"sl\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Merge für \"Full Data Training\"\n",
    "full_data_result = full_data_models.merge(\n",
    "    model_results[model_results['training_description'] == \"Full Data Training\"],\n",
    "    on=[\"dataset\", \"training_description\", \"model_name\", \"sl\"],  # Ohne \"variable\"\n",
    "    how=\"left\"\n",
    ")\n",
    "# Zusammenführen der Ergebnisse\n",
    "final_best_selection_with_test = pd.concat([id_based_result, full_data_result], ignore_index=True)\n",
    "\n",
    "# Bedingung für \"Full Data Training\"\n",
    "condition = final_best_selection_with_test['training_description'] == 'Full Data Training'\n",
    "\n",
    "# Werte in den Spalten 'variable' und 'variable_y' tauschen\n",
    "final_best_selection_with_test.loc[condition, ['variable', 'variable_y']] = \\\n",
    "    final_best_selection_with_test.loc[condition, ['variable_y', 'variable']].values\n",
    "\n",
    "\n",
    "display(final_best_selection_with_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Warnungen deaktivieren\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Ihre spezifischen Modelle\n",
    "models = [\"RFW\", \"KNNW\", \"DTW\", \"GKW\", \"LS_KDEx_LGBM\", \"LS_KDEx_MLP\", \"DRF\"]\n",
    "\n",
    "# Definieren Sie die möglichen Service Levels und Trainingsbeschreibungen\n",
    "SL_values = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "training_descriptions = [\"ID-Based Training\", \"Full Data Training\"]\n",
    "\n",
    "# Wir gehen davon aus, dass Ihre DataFrames bereits geladen sind:\n",
    "# final_best_selection_with_test, model_results, cv_results\n",
    "\n",
    "for training_description in training_descriptions:\n",
    "    for SL in SL_values:\n",
    "        # Filtern der Daten für aktuelles Service Level und Trainingsbeschreibung\n",
    "        final_best_sel = final_best_selection_with_test[\n",
    "            (final_best_selection_with_test['sl'] == SL) &\n",
    "            (final_best_selection_with_test['training_description'] == training_description)\n",
    "        ]\n",
    "\n",
    "        model_results_sel = model_results[\n",
    "            (model_results['sl'] == SL) &\n",
    "            (model_results['training_description'] == training_description)\n",
    "        ]\n",
    "\n",
    "        # Überprüfen, ob die gefilterten DataFrames nicht leer sind\n",
    "        if final_best_sel.empty or model_results_sel.empty:\n",
    "            continue\n",
    "\n",
    "        # Bereiten Sie die Daten für die Analyse vor\n",
    "        model_selection = final_best_sel[['variable', 'dataset', 'delta C']].copy()\n",
    "        model_selection.rename(columns={'delta C': 'delta_C_model_selection'}, inplace=True)\n",
    "\n",
    "        model_results_sel = model_results_sel[['variable', 'dataset', 'model_name', 'delta C']].copy()\n",
    "        model_results_sel.rename(columns={'delta C': 'delta_C_model'}, inplace=True)\n",
    "\n",
    "        # Zusammenführen der Daten basierend auf 'variable' und 'dataset'\n",
    "        merged = pd.merge(model_results_sel, model_selection, on=['variable', 'dataset'], how='left')\n",
    "\n",
    "        # Berechnen der Differenz zwischen Modellselektion und einzelnen Modellen\n",
    "        merged['∆C(model selection)-∆C(k)'] = merged['delta_C_model_selection'] - merged['delta_C_model']\n",
    "\n",
    "        # Filtern nach den gewünschten Modellen\n",
    "        merged = merged[merged['model_name'].isin(models)]\n",
    "\n",
    "        # Sicherstellen, dass 'dataset' Spalte vorhanden ist und nicht leer\n",
    "        if 'dataset' in merged.columns and not merged['dataset'].isnull().all():\n",
    "            datasets = merged['dataset'].unique()\n",
    "        else:\n",
    "            datasets = []\n",
    "\n",
    "        if len(datasets) == 0:\n",
    "            print(f\"Keine Daten zum Plotten für Training Description: {training_description}, Service Level: {SL}\")\n",
    "            continue\n",
    "\n",
    "        # Visualisierung\n",
    "        sns.set_theme(style=\"white\", font_scale=1.4)\n",
    "        g = sns.catplot(\n",
    "            y=\"model_name\",\n",
    "            x=\"∆C(model selection)-∆C(k)\",\n",
    "            data=merged,\n",
    "            kind=\"box\",\n",
    "            hue=\"model_name\",\n",
    "            col=\"dataset\",\n",
    "            col_order=datasets,\n",
    "            sharex=True,\n",
    "            sharey=False,\n",
    "            dodge=False,\n",
    "            orient='h',\n",
    "            showfliers=False,\n",
    "            height=3.75,\n",
    "            aspect=1.1,\n",
    "            legend=False\n",
    "        )\n",
    "\n",
    "        # Entfernen der Dataset-Referenz im Titel\n",
    "        g.set_titles(\"{col_name}\")  # Setzt den Dataset-Namen als Titel jedes Subplots\n",
    "\n",
    "        # Setzen der Achsenbeschriftungen\n",
    "        g.set_axis_labels(\"ΔC(Modelselektion) - ΔC(k)\", \"Modell\")\n",
    "\n",
    "        # Hinzufügen des übergeordneten Titels mit nur Training Description und Service Level\n",
    "        plt.subplots_adjust(top=0.85)\n",
    "        g.fig.suptitle(f\"Training Description: {training_description}, Service Level: {SL}\")\n",
    "\n",
    "        for ax in g.axes.flatten():\n",
    "            ax.axvline(0, color=\"black\", linestyle='--')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
